{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *SIAMESE NETWORKS* for Ad Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:57:13.205375Z",
     "start_time": "2017-11-22T04:57:13.198874Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = r\"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T04:57:26.988625Z",
     "start_time": "2017-11-22T04:57:14.326518Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/heshan/anaconda3/envs/keras_latest/lib/python3.6/site-packages/ipykernel_launcher.py:47: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/heshan/anaconda3/envs/keras_latest/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/home/heshan/anaconda3/envs/keras_latest/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38951745"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "import os\n",
    "import dill as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rng.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "#//TODO: figure out how to initialize layer biases in keras.\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rng.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "input_shape = (105, 105, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init,kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(7,7),activation='relu',\n",
    "                   kernel_regularizer=l2(2e-4),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "#encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "#merge two encoded inputs with the l1 distance between them\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "both = merge([encoded_l,encoded_r], mode = L1_distance, output_shape=lambda x: x[0])\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(both)\n",
    "siamese_net = Model(input=[left_input,right_input],output=prediction)\n",
    "#optimizer = SGD(0.0004,momentum=0.6,nesterov=True,decay=0.0003)\n",
    "\n",
    "optimizer = Adam(0.00006)\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "\n",
    "siamese_net.count_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T14:46:53.838444Z",
     "start_time": "2017-11-27T14:46:53.212232Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Siamese_Loader:\n",
    "    \"\"\"For loading batches and testing tasks to a siamese net\"\"\"\n",
    "    def __init__(self,path, genre):\n",
    "        self.data = {}\n",
    "        self.categories = {}\n",
    "        path = f\"{path}/{genre}\"\n",
    "        if genre == \"_omniglot_data\":\n",
    "            with open(os.path.join(path,\"train.pickle\"),\"rb\") as f:\n",
    "                (X,c) = pickle.load(f)\n",
    "                self.data[\"train\"] = X\n",
    "                self.categories[\"train\"] = c\n",
    "            with open(os.path.join(path,\"val.pickle\"),\"rb\") as f:\n",
    "                (X,c) = pickle.load(f)\n",
    "                self.data[\"val\"] = X\n",
    "                self.categories[\"val\"] = c\n",
    "        else:\n",
    "            with open(os.path.join(path,\"train.pickle\"),\"rb\") as f:\n",
    "                X = pickle.load(f)\n",
    "                self.data[\"train\"] = X\n",
    "            with open(os.path.join(path,\"val.pickle\"),\"rb\") as f:\n",
    "                X = pickle.load(f)\n",
    "                self.data[\"val\"] = X\n",
    "            \n",
    "        self.n_classes,self.n_examples,self.w,self.h = self.data[\"train\"].shape\n",
    "        self.n_val,self.n_ex_val,_,_ = self.data['val'].shape\n",
    "\n",
    "    def get_batch(self,n,s=\"train\"):\n",
    "        \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "        X=self.data[s]\n",
    "        categories = rng.choice(self.n_classes,size=(n,),replace=False)\n",
    "        pairs=[np.zeros((n, self.h, self.w,1)) for i in range(2)]\n",
    "        targets=np.zeros((n,))\n",
    "        targets[n//2:] = 1\n",
    "        for i in range(n):\n",
    "            category = categories[i]\n",
    "            idx_1 = rng.randint(0,self.n_examples)\n",
    "            pairs[0][i,:,:,:] = X[category,idx_1].reshape(self.w,self.h,1)\n",
    "            idx_2 = rng.randint(0,self.n_examples)\n",
    "            #pick images of same class for 1st half, different for 2nd\n",
    "            category_2 = category if i >= n//2 else (category + rng.randint(1,self.n_classes)) % self.n_classes\n",
    "            pairs[1][i,:,:,:] = X[category_2,idx_2].reshape(self.w,self.h,1)\n",
    "        return pairs, targets\n",
    "\n",
    "    def make_oneshot_task(self,N,s=\"val\"):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "        X=self.data[s]\n",
    "        n_classes, n_examples = X.shape[0],X.shape[1]\n",
    "       \n",
    "        categories = rng.choice(range(n_classes),size=(N,),replace=False)\n",
    "    \n",
    "        indices = rng.randint(0,self.n_examples,size=(N,))\n",
    "        true_category = categories[0]\n",
    "        ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "        test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N,self.w,self.h,1)\n",
    "        support_set = X[categories,indices,:,:]\n",
    "        support_set[0,:,:] = X[true_category,ex2]\n",
    "        support_set = support_set.reshape(N,self.w,self.h,1)\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1\n",
    "        targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "        pairs = [test_image,support_set]\n",
    "\n",
    "        return pairs, targets\n",
    "\n",
    "    def jam_detector(self,N=1):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "        f = open(\"./jam_bottles.pickle\", 'rb')\n",
    "        X=pickle.load(f)\n",
    "        n_classes, n_examples = X.shape[0],X.shape[1]\n",
    "        \n",
    "#         categories = np.array([0, 1])\n",
    "        \n",
    "#         indices = rng.randint(0,n_examples,size=(N,))\n",
    "        category = rng.randint(0,n_classes)\n",
    "        ex1 = rng.randint(0,n_examples)\n",
    "#         _, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "        test_image = np.asarray([X[category,ex1,:,:]]*N).reshape(N,self.w,self.h,1)\n",
    "        control = X[0,0,:,:]\n",
    "#         support_set[0,:,:] = X[true_category,ex2]\n",
    "        control = control.reshape(N,self.w,self.h,1)\n",
    "#         targets = np.zeros((N,))\n",
    "#         targets[0] = 1\n",
    "#         targets, test_image, control = shuffle(targets, test_image, control)\n",
    "        pairs = [test_image,control]\n",
    "\n",
    "        return pairs, category #, targets\n",
    "    \n",
    "    def make_සිංහල_oneshot_task(self,N,s=\"val\",language=None):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "        X=self.data[s]\n",
    "        fs = open(\"./සිංහල.pickle\", \"rb\")\n",
    "        Xs = pickle.load(fs)\n",
    "        s_classes, s_examples = Xs.shape[0], Xs.shape[1]\n",
    "        n_classes, n_examples = X.shape[0],X.shape[1]\n",
    "        \n",
    "        categories = rng.choice(range(n_classes),size=(N,),replace=False)\n",
    "        \n",
    "        indices = rng.randint(0,self.n_examples,size=(N,))\n",
    "        \n",
    "        අකුර = rng.choice(s_classes,replace=False,size=(1,))\n",
    "        \n",
    "        true_category = අකුර[0]\n",
    "        ex1, ex2 = rng.choice(s_examples,replace=False,size=(2,))\n",
    "        test_image = np.asarray([Xs[true_category,ex1,:,:]]*N).reshape(N,self.w,self.h,1)\n",
    "        support_set = X[categories,indices,:,:]\n",
    "        support_set[0,:,:] = Xs[true_category,ex2]\n",
    "        support_set = support_set.reshape(N,self.w,self.h,1)\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1\n",
    "        targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "        pairs = [test_image,support_set]\n",
    "\n",
    "        return pairs, targets \n",
    "\n",
    "    def make_adframe_sizing_oneshot_task(self,N):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "        f = open(\"./ad_frames_new.pickle\", 'rb')\n",
    "        X=pickle.load(f)\n",
    "        n_classes, n_examples = X.shape[0],X.shape[1]\n",
    "        \n",
    "        categories = rng.choice(range(n_classes),size=(N,),replace=False)\n",
    "        \n",
    "        indices = rng.randint(0,self.n_examples,size=(N,))\n",
    "        true_category = categories[0]\n",
    "        ex1 = 0\n",
    "        _, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "        test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N,self.w,self.h,1)\n",
    "        support_set = X[categories,indices,:,:]\n",
    "        support_set[0,:,:] = X[true_category,ex2]\n",
    "        support_set = support_set.reshape(N,self.w,self.h,1)\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1\n",
    "        targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "        pairs = [test_image,support_set]\n",
    "\n",
    "        return pairs, targets\n",
    "    \n",
    "    def test_oneshot(self,model,N,k,s=\"val\",verbose=0, sinhala = False, ad_frame = False):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        n_correct = 0\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} unique {} way one-shot learning tasks ...\".format(k,N))\n",
    "        if sinhala:\n",
    "            for i in range(k):\n",
    "                inputs, targets = self.make_සිංහල_oneshot_task(N,s)\n",
    "                probs = model.predict(inputs)\n",
    "                if np.argmax(probs) == np.argmax(targets):\n",
    "                    n_correct+=1\n",
    "            percent_correct = (100.0*n_correct / k)\n",
    "        elif ad_frame:\n",
    "            for i in range(k):\n",
    "                inputs, targets = self.make_adframe_oneshot_task(N)\n",
    "                probs = model.predict(inputs)\n",
    "                if np.argmax(probs) == np.argmax(targets):\n",
    "                    n_correct+=1\n",
    "            percent_correct = (100.0*n_correct / k)\n",
    "        else:\n",
    "            for i in range(k):\n",
    "                inputs, targets = self.make_oneshot_task(N,s)\n",
    "                probs = model.predict(inputs)\n",
    "                if np.argmax(probs) == np.argmax(targets):\n",
    "                    n_correct+=1\n",
    "            percent_correct = (100.0*n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy\".format(percent_correct,N))\n",
    "        return percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T14:46:58.197378Z",
     "start_time": "2017-11-27T14:46:57.736973Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loader = Siamese_Loader(file_path, \"_omniglot_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the inputs and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T11:08:38.333747Z",
     "start_time": "2017-11-27T11:08:38.056339Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc,h,w,_ = X.shape\n",
    "    X = X.reshape(nc,h,w)\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*w,n*h))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*w:(x+1)*w,y*h:(y+1)*h] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img\n",
    "\n",
    "\n",
    "def plot_oneshot_task(pairs):\n",
    "    \"\"\"Takes a one-shot task given to a siamese net and  \"\"\"\n",
    "    fig,(ax1,ax2) = plt.subplots(1,2)\n",
    "    ax1.matshow(pairs[0][0].reshape(105,105),cmap='gray')\n",
    "    img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "def plot_oneshot_result(pairs, result):\n",
    "    \"\"\"Takes a one-shot results given by siamese net and provide visual evidence\"\"\"\n",
    "    fig,(ax1,ax2, ax3) = plt.subplots(1,3)\n",
    "    ax1.matshow(pairs[0][0].reshape(105,105),cmap='gray')\n",
    "    ax2.matshow(pairs[1][0].reshape(105,105),cmap='gray')\n",
    "#     img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "#     ax2.matshow(img, cmap='gray')\n",
    "    ax3.matshow(result, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "#example of a one-shot learning task\n",
    "# pairs, targets = loader.make_oneshot_task(20,\"val\") #,\"Hebrew\")\n",
    "# plot_oneshot_task(pairs)\n",
    "# # print(targets)\n",
    "# # print(np.array(pairs))\n",
    "# print(targets.reshape(4,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T02:10:15.830830Z",
     "start_time": "2017-11-22T04:59:16.617046Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1000, training loss: 0.98,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 11.6% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 2000, training loss: 0.69,\n",
      "iteration 3000, training loss: 0.38,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 25.2% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 4000, training loss: 0.50,\n",
      "iteration 5000, training loss: 0.28,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 27.6% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 6000, training loss: 0.39,\n",
      "iteration 7000, training loss: 0.27,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 26.0% 500 way one-shot learning accuracy\n",
      "iteration 8000, training loss: 0.29,\n",
      "iteration 9000, training loss: 0.17,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 30.0% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 10000, training loss: 0.21,\n",
      "iteration 11000, training loss: 0.23,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 33.2% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 12000, training loss: 0.26,\n",
      "iteration 13000, training loss: 0.17,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 32.4% 500 way one-shot learning accuracy\n",
      "iteration 14000, training loss: 0.25,\n",
      "iteration 15000, training loss: 0.14,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 30.0% 500 way one-shot learning accuracy\n",
      "iteration 16000, training loss: 0.17,\n",
      "iteration 17000, training loss: 0.24,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 28.8% 500 way one-shot learning accuracy\n",
      "iteration 18000, training loss: 0.16,\n",
      "iteration 19000, training loss: 0.20,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 36.4% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 20000, training loss: 0.16,\n",
      "iteration 21000, training loss: 0.15,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 37.6% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 22000, training loss: 0.15,\n",
      "iteration 23000, training loss: 0.15,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 35.6% 500 way one-shot learning accuracy\n",
      "iteration 24000, training loss: 0.15,\n",
      "iteration 25000, training loss: 0.16,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 37.6% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 26000, training loss: 0.17,\n",
      "iteration 27000, training loss: 0.19,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 30.8% 500 way one-shot learning accuracy\n",
      "iteration 28000, training loss: 0.12,\n",
      "iteration 29000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 32.0% 500 way one-shot learning accuracy\n",
      "iteration 30000, training loss: 0.16,\n",
      "iteration 31000, training loss: 0.15,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 26.8% 500 way one-shot learning accuracy\n",
      "iteration 32000, training loss: 0.16,\n",
      "iteration 33000, training loss: 0.21,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.4% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 34000, training loss: 0.12,\n",
      "iteration 35000, training loss: 0.19,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 28.8% 500 way one-shot learning accuracy\n",
      "iteration 36000, training loss: 0.12,\n",
      "iteration 37000, training loss: 0.14,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.4% 500 way one-shot learning accuracy\n",
      "iteration 38000, training loss: 0.20,\n",
      "iteration 39000, training loss: 0.14,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 34.4% 500 way one-shot learning accuracy\n",
      "iteration 40000, training loss: 0.12,\n",
      "iteration 41000, training loss: 0.27,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 35.2% 500 way one-shot learning accuracy\n",
      "iteration 42000, training loss: 0.17,\n",
      "iteration 43000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 44000, training loss: 0.13,\n",
      "iteration 45000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 39.6% 500 way one-shot learning accuracy\n",
      "iteration 46000, training loss: 0.17,\n",
      "iteration 47000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 48000, training loss: 0.18,\n",
      "iteration 49000, training loss: 0.23,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 39.6% 500 way one-shot learning accuracy\n",
      "iteration 50000, training loss: 0.11,\n",
      "iteration 51000, training loss: 0.14,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.0% 500 way one-shot learning accuracy\n",
      "iteration 52000, training loss: 0.21,\n",
      "iteration 53000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 39.2% 500 way one-shot learning accuracy\n",
      "iteration 54000, training loss: 0.14,\n",
      "iteration 55000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 56000, training loss: 0.15,\n",
      "iteration 57000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.0% 500 way one-shot learning accuracy\n",
      "iteration 58000, training loss: 0.19,\n",
      "iteration 59000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 60000, training loss: 0.12,\n",
      "iteration 61000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.8% 500 way one-shot learning accuracy\n",
      "iteration 62000, training loss: 0.16,\n",
      "iteration 63000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.8% 500 way one-shot learning accuracy\n",
      "iteration 64000, training loss: 0.11,\n",
      "iteration 65000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.8% 500 way one-shot learning accuracy\n",
      "iteration 66000, training loss: 0.15,\n",
      "iteration 67000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 34.8% 500 way one-shot learning accuracy\n",
      "iteration 68000, training loss: 0.13,\n",
      "iteration 69000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 70000, training loss: 0.10,\n",
      "iteration 71000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 72000, training loss: 0.16,\n",
      "iteration 73000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.2% 500 way one-shot learning accuracy\n",
      "iteration 74000, training loss: 0.10,\n",
      "iteration 75000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 76000, training loss: 0.15,\n",
      "iteration 77000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.6% 500 way one-shot learning accuracy\n",
      "iteration 78000, training loss: 0.09,\n",
      "iteration 79000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 80000, training loss: 0.10,\n",
      "iteration 81000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 38.0% 500 way one-shot learning accuracy\n",
      "iteration 82000, training loss: 0.09,\n",
      "iteration 83000, training loss: 0.33,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 84000, training loss: 0.09,\n",
      "iteration 85000, training loss: 0.15,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 86000, training loss: 0.16,\n",
      "iteration 87000, training loss: 0.18,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.4% 500 way one-shot learning accuracy\n",
      "iteration 88000, training loss: 0.10,\n",
      "iteration 89000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 90000, training loss: 0.20,\n",
      "iteration 91000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.4% 500 way one-shot learning accuracy\n",
      "iteration 92000, training loss: 0.18,\n",
      "iteration 93000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 94000, training loss: 0.09,\n",
      "iteration 95000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.0% 500 way one-shot learning accuracy\n",
      "iteration 96000, training loss: 0.10,\n",
      "iteration 97000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 98000, training loss: 0.10,\n",
      "iteration 99000, training loss: 0.22,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 100000, training loss: 0.09,\n",
      "iteration 101000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 102000, training loss: 0.10,\n",
      "iteration 103000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 104000, training loss: 0.09,\n",
      "iteration 105000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 36.8% 500 way one-shot learning accuracy\n",
      "iteration 106000, training loss: 0.09,\n",
      "iteration 107000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.4% 500 way one-shot learning accuracy\n",
      "iteration 108000, training loss: 0.09,\n",
      "iteration 109000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 110000, training loss: 0.08,\n",
      "iteration 111000, training loss: 0.22,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.8% 500 way one-shot learning accuracy\n",
      "iteration 112000, training loss: 0.19,\n",
      "iteration 113000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 114000, training loss: 0.14,\n",
      "iteration 115000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.8% 500 way one-shot learning accuracy\n",
      "iteration 116000, training loss: 0.10,\n",
      "iteration 117000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.2% 500 way one-shot learning accuracy\n",
      "iteration 118000, training loss: 0.08,\n",
      "iteration 119000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 120000, training loss: 0.10,\n",
      "iteration 121000, training loss: 0.15,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 122000, training loss: 0.09,\n",
      "iteration 123000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 124000, training loss: 0.08,\n",
      "iteration 125000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 126000, training loss: 0.09,\n",
      "iteration 127000, training loss: 0.19,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 39.2% 500 way one-shot learning accuracy\n",
      "iteration 128000, training loss: 0.12,\n",
      "iteration 129000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.8% 500 way one-shot learning accuracy\n",
      "iteration 130000, training loss: 0.09,\n",
      "iteration 131000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 132000, training loss: 0.09,\n",
      "iteration 133000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 36.0% 500 way one-shot learning accuracy\n",
      "iteration 134000, training loss: 0.08,\n",
      "iteration 135000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 136000, training loss: 0.10,\n",
      "iteration 137000, training loss: 0.19,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 138000, training loss: 0.11,\n",
      "iteration 139000, training loss: 0.16,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 140000, training loss: 0.08,\n",
      "iteration 141000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 142000, training loss: 0.09,\n",
      "iteration 143000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 144000, training loss: 0.18,\n",
      "iteration 145000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 146000, training loss: 0.10,\n",
      "iteration 147000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 148000, training loss: 0.11,\n",
      "iteration 149000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 150000, training loss: 0.08,\n",
      "iteration 151000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 152000, training loss: 0.09,\n",
      "iteration 153000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 154000, training loss: 0.09,\n",
      "iteration 155000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 37.6% 500 way one-shot learning accuracy\n",
      "iteration 156000, training loss: 0.08,\n",
      "iteration 157000, training loss: 0.14,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 158000, training loss: 0.08,\n",
      "iteration 159000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 160000, training loss: 0.10,\n",
      "iteration 161000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 162000, training loss: 0.08,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 163000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.2% 500 way one-shot learning accuracy\n",
      "iteration 164000, training loss: 0.12,\n",
      "iteration 165000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 166000, training loss: 0.09,\n",
      "iteration 167000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 168000, training loss: 0.10,\n",
      "iteration 169000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.4% 500 way one-shot learning accuracy\n",
      "iteration 170000, training loss: 0.09,\n",
      "iteration 171000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 172000, training loss: 0.18,\n",
      "iteration 173000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.4% 500 way one-shot learning accuracy\n",
      "iteration 174000, training loss: 0.10,\n",
      "iteration 175000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.4% 500 way one-shot learning accuracy\n",
      "iteration 176000, training loss: 0.10,\n",
      "iteration 177000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 178000, training loss: 0.09,\n",
      "iteration 179000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 180000, training loss: 0.08,\n",
      "iteration 181000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 182000, training loss: 0.08,\n",
      "iteration 183000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 184000, training loss: 0.17,\n",
      "iteration 185000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.2% 500 way one-shot learning accuracy\n",
      "iteration 186000, training loss: 0.08,\n",
      "iteration 187000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 188000, training loss: 0.09,\n",
      "iteration 189000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 190000, training loss: 0.07,\n",
      "iteration 191000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 192000, training loss: 0.08,\n",
      "iteration 193000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 194000, training loss: 0.08,\n",
      "iteration 195000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 196000, training loss: 0.09,\n",
      "iteration 197000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 198000, training loss: 0.07,\n",
      "iteration 199000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 200000, training loss: 0.09,\n",
      "iteration 201000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.2% 500 way one-shot learning accuracy\n",
      "iteration 202000, training loss: 0.10,\n",
      "iteration 203000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 204000, training loss: 0.09,\n",
      "iteration 205000, training loss: 0.19,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 39.2% 500 way one-shot learning accuracy\n",
      "iteration 206000, training loss: 0.07,\n",
      "iteration 207000, training loss: 0.18,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 208000, training loss: 0.09,\n",
      "iteration 209000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 210000, training loss: 0.08,\n",
      "iteration 211000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 212000, training loss: 0.23,\n",
      "iteration 213000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 214000, training loss: 0.19,\n",
      "iteration 215000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 216000, training loss: 0.07,\n",
      "iteration 217000, training loss: 0.17,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 218000, training loss: 0.12,\n",
      "iteration 219000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 220000, training loss: 0.08,\n",
      "iteration 221000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 222000, training loss: 0.19,\n",
      "iteration 223000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 224000, training loss: 0.08,\n",
      "iteration 225000, training loss: 0.29,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 226000, training loss: 0.08,\n",
      "iteration 227000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 228000, training loss: 0.07,\n",
      "iteration 229000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 230000, training loss: 0.07,\n",
      "iteration 231000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 232000, training loss: 0.19,\n",
      "iteration 233000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 234000, training loss: 0.09,\n",
      "iteration 235000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 236000, training loss: 0.08,\n",
      "iteration 237000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 238000, training loss: 0.12,\n",
      "iteration 239000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 240000, training loss: 0.07,\n",
      "iteration 241000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 242000, training loss: 0.10,\n",
      "iteration 243000, training loss: 0.08,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 244000, training loss: 0.07,\n",
      "iteration 245000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 246000, training loss: 0.07,\n",
      "iteration 247000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 248000, training loss: 0.07,\n",
      "iteration 249000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 250000, training loss: 0.08,\n",
      "iteration 251000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 252000, training loss: 0.08,\n",
      "iteration 253000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.0% 500 way one-shot learning accuracy\n",
      "iteration 254000, training loss: 0.07,\n",
      "iteration 255000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 256000, training loss: 0.07,\n",
      "iteration 257000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 258000, training loss: 0.07,\n",
      "iteration 259000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 260000, training loss: 0.22,\n",
      "iteration 261000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.4% 500 way one-shot learning accuracy\n",
      "iteration 262000, training loss: 0.13,\n",
      "iteration 263000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 264000, training loss: 0.07,\n",
      "iteration 265000, training loss: 0.16,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 266000, training loss: 0.07,\n",
      "iteration 267000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 39.6% 500 way one-shot learning accuracy\n",
      "iteration 268000, training loss: 0.10,\n",
      "iteration 269000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 270000, training loss: 0.07,\n",
      "iteration 271000, training loss: 0.25,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 272000, training loss: 0.08,\n",
      "iteration 273000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 274000, training loss: 0.07,\n",
      "iteration 275000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 276000, training loss: 0.07,\n",
      "iteration 277000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 278000, training loss: 0.07,\n",
      "iteration 279000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 280000, training loss: 0.13,\n",
      "iteration 281000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 282000, training loss: 0.07,\n",
      "iteration 283000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 284000, training loss: 0.27,\n",
      "iteration 285000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.6% 500 way one-shot learning accuracy\n",
      "iteration 286000, training loss: 0.08,\n",
      "iteration 287000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.2% 500 way one-shot learning accuracy\n",
      "iteration 288000, training loss: 0.07,\n",
      "iteration 289000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 290000, training loss: 0.09,\n",
      "iteration 291000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 292000, training loss: 0.09,\n",
      "iteration 293000, training loss: 0.16,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 294000, training loss: 0.10,\n",
      "iteration 295000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 296000, training loss: 0.07,\n",
      "iteration 297000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 298000, training loss: 0.07,\n",
      "iteration 299000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 300000, training loss: 0.07,\n",
      "iteration 301000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 302000, training loss: 0.10,\n",
      "iteration 303000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 304000, training loss: 0.08,\n",
      "iteration 305000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 306000, training loss: 0.07,\n",
      "iteration 307000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.0% 500 way one-shot learning accuracy\n",
      "iteration 308000, training loss: 0.07,\n",
      "iteration 309000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 310000, training loss: 0.08,\n",
      "iteration 311000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 312000, training loss: 0.14,\n",
      "iteration 313000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 314000, training loss: 0.07,\n",
      "iteration 315000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 316000, training loss: 0.07,\n",
      "iteration 317000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 318000, training loss: 0.07,\n",
      "iteration 319000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 320000, training loss: 0.07,\n",
      "iteration 321000, training loss: 0.21,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 39.2% 500 way one-shot learning accuracy\n",
      "iteration 322000, training loss: 0.07,\n",
      "iteration 323000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 324000, training loss: 0.07,\n",
      "iteration 325000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 326000, training loss: 0.11,\n",
      "iteration 327000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 328000, training loss: 0.07,\n",
      "iteration 329000, training loss: 0.24,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 330000, training loss: 0.07,\n",
      "iteration 331000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 332000, training loss: 0.07,\n",
      "iteration 333000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 334000, training loss: 0.07,\n",
      "iteration 335000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 336000, training loss: 0.09,\n",
      "iteration 337000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 338000, training loss: 0.06,\n",
      "iteration 339000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 340000, training loss: 0.06,\n",
      "iteration 341000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 342000, training loss: 0.07,\n",
      "iteration 343000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 344000, training loss: 0.07,\n",
      "iteration 345000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 346000, training loss: 0.06,\n",
      "iteration 347000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 348000, training loss: 0.06,\n",
      "iteration 349000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 350000, training loss: 0.06,\n",
      "iteration 351000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 352000, training loss: 0.08,\n",
      "iteration 353000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.4% 500 way one-shot learning accuracy\n",
      "iteration 354000, training loss: 0.13,\n",
      "iteration 355000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 356000, training loss: 0.16,\n",
      "iteration 357000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 358000, training loss: 0.07,\n",
      "iteration 359000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 360000, training loss: 0.08,\n",
      "iteration 361000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 362000, training loss: 0.08,\n",
      "iteration 363000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 364000, training loss: 0.07,\n",
      "iteration 365000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 366000, training loss: 0.15,\n",
      "iteration 367000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 368000, training loss: 0.22,\n",
      "iteration 369000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 370000, training loss: 0.13,\n",
      "iteration 371000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 372000, training loss: 0.06,\n",
      "iteration 373000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 374000, training loss: 0.07,\n",
      "iteration 375000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 376000, training loss: 0.12,\n",
      "iteration 377000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 378000, training loss: 0.13,\n",
      "iteration 379000, training loss: 0.15,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 380000, training loss: 0.06,\n",
      "iteration 381000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 382000, training loss: 0.09,\n",
      "iteration 383000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 384000, training loss: 0.07,\n",
      "iteration 385000, training loss: 0.16,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 386000, training loss: 0.07,\n",
      "iteration 387000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 388000, training loss: 0.08,\n",
      "iteration 389000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 390000, training loss: 0.06,\n",
      "iteration 391000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 392000, training loss: 0.09,\n",
      "iteration 393000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 394000, training loss: 0.08,\n",
      "iteration 395000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 396000, training loss: 0.10,\n",
      "iteration 397000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 398000, training loss: 0.07,\n",
      "iteration 399000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 400000, training loss: 0.11,\n",
      "iteration 401000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 402000, training loss: 0.12,\n",
      "iteration 403000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 404000, training loss: 0.06,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 405000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 406000, training loss: 0.07,\n",
      "iteration 407000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 408000, training loss: 0.07,\n",
      "iteration 409000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 410000, training loss: 0.09,\n",
      "iteration 411000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 412000, training loss: 0.06,\n",
      "iteration 413000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 414000, training loss: 0.06,\n",
      "iteration 415000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 416000, training loss: 0.06,\n",
      "iteration 417000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 418000, training loss: 0.07,\n",
      "iteration 419000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 420000, training loss: 0.06,\n",
      "iteration 421000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 422000, training loss: 0.07,\n",
      "iteration 423000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 424000, training loss: 0.07,\n",
      "iteration 425000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 426000, training loss: 0.06,\n",
      "iteration 427000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 428000, training loss: 0.23,\n",
      "iteration 429000, training loss: 0.22,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 430000, training loss: 0.06,\n",
      "iteration 431000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 432000, training loss: 0.12,\n",
      "iteration 433000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 434000, training loss: 0.07,\n",
      "iteration 435000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 436000, training loss: 0.07,\n",
      "iteration 437000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 438000, training loss: 0.11,\n",
      "iteration 439000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 440000, training loss: 0.06,\n",
      "iteration 441000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 442000, training loss: 0.07,\n",
      "iteration 443000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.2% 500 way one-shot learning accuracy\n",
      "iteration 444000, training loss: 0.06,\n",
      "iteration 445000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 446000, training loss: 0.06,\n",
      "iteration 447000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 448000, training loss: 0.11,\n",
      "iteration 449000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 450000, training loss: 0.06,\n",
      "iteration 451000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 452000, training loss: 0.06,\n",
      "iteration 453000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 454000, training loss: 0.06,\n",
      "iteration 455000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 456000, training loss: 0.06,\n",
      "iteration 457000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 458000, training loss: 0.07,\n",
      "iteration 459000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 460000, training loss: 0.06,\n",
      "iteration 461000, training loss: 0.18,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 462000, training loss: 0.08,\n",
      "iteration 463000, training loss: 0.14,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 464000, training loss: 0.06,\n",
      "iteration 465000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 466000, training loss: 0.06,\n",
      "iteration 467000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.0% 500 way one-shot learning accuracy\n",
      "iteration 468000, training loss: 0.06,\n",
      "iteration 469000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.6% 500 way one-shot learning accuracy\n",
      "iteration 470000, training loss: 0.06,\n",
      "iteration 471000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 472000, training loss: 0.06,\n",
      "iteration 473000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 474000, training loss: 0.06,\n",
      "iteration 475000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 476000, training loss: 0.06,\n",
      "iteration 477000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 478000, training loss: 0.06,\n",
      "iteration 479000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 480000, training loss: 0.06,\n",
      "iteration 481000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 482000, training loss: 0.06,\n",
      "iteration 483000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 484000, training loss: 0.07,\n",
      "iteration 485000, training loss: 0.10,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 486000, training loss: 0.08,\n",
      "iteration 487000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 488000, training loss: 0.06,\n",
      "iteration 489000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 490000, training loss: 0.06,\n",
      "iteration 491000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 492000, training loss: 0.06,\n",
      "iteration 493000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 494000, training loss: 0.06,\n",
      "iteration 495000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 496000, training loss: 0.06,\n",
      "iteration 497000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 498000, training loss: 0.06,\n",
      "iteration 499000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 500000, training loss: 0.07,\n",
      "iteration 501000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 502000, training loss: 0.06,\n",
      "iteration 503000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 504000, training loss: 0.07,\n",
      "iteration 505000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 506000, training loss: 0.07,\n",
      "iteration 507000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 508000, training loss: 0.06,\n",
      "iteration 509000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 510000, training loss: 0.10,\n",
      "iteration 511000, training loss: 0.18,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 512000, training loss: 0.07,\n",
      "iteration 513000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 514000, training loss: 0.15,\n",
      "iteration 515000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 516000, training loss: 0.06,\n",
      "iteration 517000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 518000, training loss: 0.06,\n",
      "iteration 519000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 520000, training loss: 0.06,\n",
      "iteration 521000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 522000, training loss: 0.08,\n",
      "iteration 523000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 524000, training loss: 0.06,\n",
      "iteration 525000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 526000, training loss: 0.06,\n",
      "iteration 527000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 528000, training loss: 0.08,\n",
      "iteration 529000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 530000, training loss: 0.06,\n",
      "iteration 531000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 532000, training loss: 0.06,\n",
      "iteration 533000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 534000, training loss: 0.06,\n",
      "iteration 535000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 536000, training loss: 0.06,\n",
      "iteration 537000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 538000, training loss: 0.06,\n",
      "iteration 539000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 540000, training loss: 0.07,\n",
      "iteration 541000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 542000, training loss: 0.07,\n",
      "iteration 543000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 544000, training loss: 0.10,\n",
      "iteration 545000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 546000, training loss: 0.07,\n",
      "iteration 547000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 548000, training loss: 0.14,\n",
      "iteration 549000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 550000, training loss: 0.06,\n",
      "iteration 551000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 552000, training loss: 0.06,\n",
      "iteration 553000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 554000, training loss: 0.05,\n",
      "iteration 555000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 556000, training loss: 0.06,\n",
      "iteration 557000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 558000, training loss: 0.08,\n",
      "iteration 559000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 560000, training loss: 0.06,\n",
      "iteration 561000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 562000, training loss: 0.07,\n",
      "iteration 563000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 564000, training loss: 0.06,\n",
      "iteration 565000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 566000, training loss: 0.06,\n",
      "iteration 567000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 568000, training loss: 0.06,\n",
      "iteration 569000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 570000, training loss: 0.06,\n",
      "iteration 571000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 572000, training loss: 0.06,\n",
      "iteration 573000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 574000, training loss: 0.06,\n",
      "iteration 575000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 576000, training loss: 0.06,\n",
      "iteration 577000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 578000, training loss: 0.08,\n",
      "iteration 579000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 580000, training loss: 0.05,\n",
      "iteration 581000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 582000, training loss: 0.08,\n",
      "iteration 583000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 584000, training loss: 0.06,\n",
      "iteration 585000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 586000, training loss: 0.06,\n",
      "iteration 587000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.8% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 588000, training loss: 0.09,\n",
      "iteration 589000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 590000, training loss: 0.06,\n",
      "iteration 591000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 592000, training loss: 0.06,\n",
      "iteration 593000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 594000, training loss: 0.17,\n",
      "iteration 595000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 596000, training loss: 0.06,\n",
      "iteration 597000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 598000, training loss: 0.06,\n",
      "iteration 599000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 600000, training loss: 0.06,\n",
      "iteration 601000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 602000, training loss: 0.06,\n",
      "iteration 603000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 604000, training loss: 0.06,\n",
      "iteration 605000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 606000, training loss: 0.07,\n",
      "iteration 607000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 608000, training loss: 0.07,\n",
      "iteration 609000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 610000, training loss: 0.07,\n",
      "iteration 611000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 612000, training loss: 0.05,\n",
      "iteration 613000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 614000, training loss: 0.06,\n",
      "iteration 615000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 616000, training loss: 0.06,\n",
      "iteration 617000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 618000, training loss: 0.06,\n",
      "iteration 619000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 620000, training loss: 0.06,\n",
      "iteration 621000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 622000, training loss: 0.06,\n",
      "iteration 623000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 624000, training loss: 0.14,\n",
      "iteration 625000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 626000, training loss: 0.05,\n",
      "iteration 627000, training loss: 0.15,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 628000, training loss: 0.06,\n",
      "iteration 629000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 630000, training loss: 0.10,\n",
      "iteration 631000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 632000, training loss: 0.07,\n",
      "iteration 633000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 634000, training loss: 0.06,\n",
      "iteration 635000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.8% 500 way one-shot learning accuracy\n",
      "iteration 636000, training loss: 0.05,\n",
      "iteration 637000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 638000, training loss: 0.05,\n",
      "iteration 639000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 640000, training loss: 0.06,\n",
      "iteration 641000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 642000, training loss: 0.19,\n",
      "iteration 643000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 40.0% 500 way one-shot learning accuracy\n",
      "iteration 644000, training loss: 0.05,\n",
      "iteration 645000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 646000, training loss: 0.07,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 647000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 648000, training loss: 0.24,\n",
      "iteration 649000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 650000, training loss: 0.06,\n",
      "iteration 651000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 652000, training loss: 0.05,\n",
      "iteration 653000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 654000, training loss: 0.06,\n",
      "iteration 655000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 656000, training loss: 0.05,\n",
      "iteration 657000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 658000, training loss: 0.05,\n",
      "iteration 659000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 660000, training loss: 0.05,\n",
      "iteration 661000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 662000, training loss: 0.19,\n",
      "iteration 663000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 664000, training loss: 0.05,\n",
      "iteration 665000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 666000, training loss: 0.06,\n",
      "iteration 667000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 668000, training loss: 0.05,\n",
      "iteration 669000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 670000, training loss: 0.05,\n",
      "iteration 671000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 672000, training loss: 0.05,\n",
      "iteration 673000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 674000, training loss: 0.07,\n",
      "iteration 675000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 676000, training loss: 0.05,\n",
      "iteration 677000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 678000, training loss: 0.06,\n",
      "iteration 679000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.4% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 680000, training loss: 0.05,\n",
      "iteration 681000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 682000, training loss: 0.08,\n",
      "iteration 683000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 684000, training loss: 0.05,\n",
      "iteration 685000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 686000, training loss: 0.06,\n",
      "iteration 687000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 688000, training loss: 0.05,\n",
      "iteration 689000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 690000, training loss: 0.05,\n",
      "iteration 691000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 692000, training loss: 0.05,\n",
      "iteration 693000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 694000, training loss: 0.05,\n",
      "iteration 695000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 696000, training loss: 0.06,\n",
      "iteration 697000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 698000, training loss: 0.07,\n",
      "iteration 699000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 700000, training loss: 0.06,\n",
      "iteration 701000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 702000, training loss: 0.05,\n",
      "iteration 703000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 704000, training loss: 0.05,\n",
      "iteration 705000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 706000, training loss: 0.09,\n",
      "iteration 707000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 708000, training loss: 0.07,\n",
      "iteration 709000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 710000, training loss: 0.05,\n",
      "iteration 711000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 712000, training loss: 0.06,\n",
      "iteration 713000, training loss: 0.21,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 57.6% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 714000, training loss: 0.08,\n",
      "iteration 715000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 716000, training loss: 0.10,\n",
      "iteration 717000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 718000, training loss: 0.05,\n",
      "iteration 719000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 720000, training loss: 0.06,\n",
      "iteration 721000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 722000, training loss: 0.05,\n",
      "iteration 723000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 724000, training loss: 0.05,\n",
      "iteration 725000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.2% 500 way one-shot learning accuracy\n",
      "iteration 726000, training loss: 0.05,\n",
      "iteration 727000, training loss: 0.05,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 728000, training loss: 0.05,\n",
      "iteration 729000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 730000, training loss: 0.06,\n",
      "iteration 731000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 732000, training loss: 0.05,\n",
      "iteration 733000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 734000, training loss: 0.05,\n",
      "iteration 735000, training loss: 0.14,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 736000, training loss: 0.05,\n",
      "iteration 737000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 738000, training loss: 0.05,\n",
      "iteration 739000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 740000, training loss: 0.09,\n",
      "iteration 741000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 742000, training loss: 0.07,\n",
      "iteration 743000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 744000, training loss: 0.05,\n",
      "iteration 745000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 746000, training loss: 0.05,\n",
      "iteration 747000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 748000, training loss: 0.07,\n",
      "iteration 749000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 750000, training loss: 0.14,\n",
      "iteration 751000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 39.6% 500 way one-shot learning accuracy\n",
      "iteration 752000, training loss: 0.10,\n",
      "iteration 753000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 754000, training loss: 0.05,\n",
      "iteration 755000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 756000, training loss: 0.05,\n",
      "iteration 757000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 758000, training loss: 0.13,\n",
      "iteration 759000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 760000, training loss: 0.05,\n",
      "iteration 761000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 762000, training loss: 0.05,\n",
      "iteration 763000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 764000, training loss: 0.07,\n",
      "iteration 765000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 766000, training loss: 0.05,\n",
      "iteration 767000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 768000, training loss: 0.05,\n",
      "iteration 769000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 770000, training loss: 0.05,\n",
      "iteration 771000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 772000, training loss: 0.05,\n",
      "iteration 773000, training loss: 0.18,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 774000, training loss: 0.05,\n",
      "iteration 775000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 776000, training loss: 0.04,\n",
      "iteration 777000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 778000, training loss: 0.06,\n",
      "iteration 779000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 780000, training loss: 0.05,\n",
      "iteration 781000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 782000, training loss: 0.05,\n",
      "iteration 783000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 784000, training loss: 0.05,\n",
      "iteration 785000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 786000, training loss: 0.05,\n",
      "iteration 787000, training loss: 0.28,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 788000, training loss: 0.05,\n",
      "iteration 789000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 790000, training loss: 0.05,\n",
      "iteration 791000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 792000, training loss: 0.05,\n",
      "iteration 793000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 794000, training loss: 0.06,\n",
      "iteration 795000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 796000, training loss: 0.06,\n",
      "iteration 797000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 798000, training loss: 0.06,\n",
      "iteration 799000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 800000, training loss: 0.05,\n",
      "iteration 801000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 802000, training loss: 0.05,\n",
      "iteration 803000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 804000, training loss: 0.10,\n",
      "iteration 805000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 806000, training loss: 0.04,\n",
      "iteration 807000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 808000, training loss: 0.20,\n",
      "iteration 809000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 810000, training loss: 0.05,\n",
      "iteration 811000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 812000, training loss: 0.04,\n",
      "iteration 813000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 814000, training loss: 0.05,\n",
      "iteration 815000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 816000, training loss: 0.05,\n",
      "iteration 817000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 818000, training loss: 0.06,\n",
      "iteration 819000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 820000, training loss: 0.05,\n",
      "iteration 821000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 822000, training loss: 0.05,\n",
      "iteration 823000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 824000, training loss: 0.05,\n",
      "iteration 825000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 826000, training loss: 0.06,\n",
      "iteration 827000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 828000, training loss: 0.04,\n",
      "iteration 829000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.6% 500 way one-shot learning accuracy\n",
      "iteration 830000, training loss: 0.04,\n",
      "iteration 831000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 832000, training loss: 0.15,\n",
      "iteration 833000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 834000, training loss: 0.04,\n",
      "iteration 835000, training loss: 0.27,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 836000, training loss: 0.06,\n",
      "iteration 837000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 838000, training loss: 0.06,\n",
      "iteration 839000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 840000, training loss: 0.04,\n",
      "iteration 841000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 842000, training loss: 0.05,\n",
      "iteration 843000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 844000, training loss: 0.05,\n",
      "iteration 845000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 846000, training loss: 0.05,\n",
      "iteration 847000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 848000, training loss: 0.10,\n",
      "iteration 849000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 850000, training loss: 0.05,\n",
      "iteration 851000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 852000, training loss: 0.05,\n",
      "iteration 853000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 854000, training loss: 0.06,\n",
      "iteration 855000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 856000, training loss: 0.05,\n",
      "iteration 857000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 858000, training loss: 0.05,\n",
      "iteration 859000, training loss: 0.14,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 860000, training loss: 0.05,\n",
      "iteration 861000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 862000, training loss: 0.09,\n",
      "iteration 863000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 864000, training loss: 0.05,\n",
      "iteration 865000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 866000, training loss: 0.05,\n",
      "iteration 867000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 868000, training loss: 0.05,\n",
      "iteration 869000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 870000, training loss: 0.34,\n",
      "iteration 871000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 872000, training loss: 0.08,\n",
      "iteration 873000, training loss: 0.24,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 874000, training loss: 0.05,\n",
      "iteration 875000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 876000, training loss: 0.05,\n",
      "iteration 877000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 878000, training loss: 0.04,\n",
      "iteration 879000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 880000, training loss: 0.05,\n",
      "iteration 881000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 882000, training loss: 0.05,\n",
      "iteration 883000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 884000, training loss: 0.06,\n",
      "iteration 885000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 886000, training loss: 0.04,\n",
      "iteration 887000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 888000, training loss: 0.17,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 889000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 890000, training loss: 0.06,\n",
      "iteration 891000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 892000, training loss: 0.07,\n",
      "iteration 893000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 894000, training loss: 0.04,\n",
      "iteration 895000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 896000, training loss: 0.05,\n",
      "iteration 897000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 898000, training loss: 0.04,\n",
      "iteration 899000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 900000, training loss: 0.06,\n",
      "iteration 901000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 902000, training loss: 0.10,\n",
      "iteration 903000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 904000, training loss: 0.04,\n",
      "iteration 905000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 906000, training loss: 0.05,\n",
      "iteration 907000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 908000, training loss: 0.04,\n",
      "iteration 909000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 910000, training loss: 0.04,\n",
      "iteration 911000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 912000, training loss: 0.04,\n",
      "iteration 913000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 914000, training loss: 0.07,\n",
      "iteration 915000, training loss: 0.15,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 916000, training loss: 0.05,\n",
      "iteration 917000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.6% 500 way one-shot learning accuracy\n",
      "iteration 918000, training loss: 0.05,\n",
      "iteration 919000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 920000, training loss: 0.16,\n",
      "iteration 921000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 922000, training loss: 0.04,\n",
      "iteration 923000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 924000, training loss: 0.05,\n",
      "iteration 925000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 926000, training loss: 0.06,\n",
      "iteration 927000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 928000, training loss: 0.25,\n",
      "iteration 929000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 930000, training loss: 0.04,\n",
      "iteration 931000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 932000, training loss: 0.05,\n",
      "iteration 933000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 934000, training loss: 0.05,\n",
      "iteration 935000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 936000, training loss: 0.05,\n",
      "iteration 937000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 938000, training loss: 0.06,\n",
      "iteration 939000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 940000, training loss: 0.05,\n",
      "iteration 941000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 942000, training loss: 0.05,\n",
      "iteration 943000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 944000, training loss: 0.04,\n",
      "iteration 945000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 946000, training loss: 0.04,\n",
      "iteration 947000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 948000, training loss: 0.04,\n",
      "iteration 949000, training loss: 0.19,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 950000, training loss: 0.04,\n",
      "iteration 951000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 952000, training loss: 0.04,\n",
      "iteration 953000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.6% 500 way one-shot learning accuracy\n",
      "iteration 954000, training loss: 0.05,\n",
      "iteration 955000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 956000, training loss: 0.04,\n",
      "iteration 957000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 958000, training loss: 0.04,\n",
      "iteration 959000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 960000, training loss: 0.12,\n",
      "iteration 961000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 962000, training loss: 0.06,\n",
      "iteration 963000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 964000, training loss: 0.06,\n",
      "iteration 965000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 966000, training loss: 0.04,\n",
      "iteration 967000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 968000, training loss: 0.05,\n",
      "iteration 969000, training loss: 0.04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 970000, training loss: 0.04,\n",
      "iteration 971000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 972000, training loss: 0.04,\n",
      "iteration 973000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 974000, training loss: 0.05,\n",
      "iteration 975000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 976000, training loss: 0.06,\n",
      "iteration 977000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 978000, training loss: 0.05,\n",
      "iteration 979000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 980000, training loss: 0.05,\n",
      "iteration 981000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 982000, training loss: 0.05,\n",
      "iteration 983000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 984000, training loss: 0.05,\n",
      "iteration 985000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 986000, training loss: 0.04,\n",
      "iteration 987000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 988000, training loss: 0.09,\n",
      "iteration 989000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 990000, training loss: 0.05,\n",
      "iteration 991000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 992000, training loss: 0.10,\n",
      "iteration 993000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 994000, training loss: 0.04,\n",
      "iteration 995000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 996000, training loss: 0.04,\n",
      "iteration 997000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 998000, training loss: 0.05,\n",
      "iteration 999000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1000000, training loss: 0.05,\n",
      "iteration 1001000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1002000, training loss: 0.05,\n",
      "iteration 1003000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 1004000, training loss: 0.05,\n",
      "iteration 1005000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1006000, training loss: 0.04,\n",
      "iteration 1007000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1008000, training loss: 0.05,\n",
      "iteration 1009000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1010000, training loss: 0.08,\n",
      "iteration 1011000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 1012000, training loss: 0.05,\n",
      "iteration 1013000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 1014000, training loss: 0.05,\n",
      "iteration 1015000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 1016000, training loss: 0.05,\n",
      "iteration 1017000, training loss: 0.16,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 41.6% 500 way one-shot learning accuracy\n",
      "iteration 1018000, training loss: 0.07,\n",
      "iteration 1019000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1020000, training loss: 0.04,\n",
      "iteration 1021000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1022000, training loss: 0.04,\n",
      "iteration 1023000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 1024000, training loss: 0.10,\n",
      "iteration 1025000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1026000, training loss: 0.14,\n",
      "iteration 1027000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1028000, training loss: 0.04,\n",
      "iteration 1029000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1030000, training loss: 0.05,\n",
      "iteration 1031000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1032000, training loss: 0.04,\n",
      "iteration 1033000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 1034000, training loss: 0.04,\n",
      "iteration 1035000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1036000, training loss: 0.04,\n",
      "iteration 1037000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1038000, training loss: 0.05,\n",
      "iteration 1039000, training loss: 0.20,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 1040000, training loss: 0.10,\n",
      "iteration 1041000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1042000, training loss: 0.05,\n",
      "iteration 1043000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1044000, training loss: 0.04,\n",
      "iteration 1045000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 1046000, training loss: 0.04,\n",
      "iteration 1047000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1048000, training loss: 0.05,\n",
      "iteration 1049000, training loss: 0.05,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1050000, training loss: 0.05,\n",
      "iteration 1051000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 1052000, training loss: 0.05,\n",
      "iteration 1053000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 1054000, training loss: 0.11,\n",
      "iteration 1055000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1056000, training loss: 0.04,\n",
      "iteration 1057000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1058000, training loss: 0.14,\n",
      "iteration 1059000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1060000, training loss: 0.04,\n",
      "iteration 1061000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1062000, training loss: 0.04,\n",
      "iteration 1063000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1064000, training loss: 0.04,\n",
      "iteration 1065000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1066000, training loss: 0.05,\n",
      "iteration 1067000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1068000, training loss: 0.05,\n",
      "iteration 1069000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1070000, training loss: 0.04,\n",
      "iteration 1071000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1072000, training loss: 0.05,\n",
      "iteration 1073000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1074000, training loss: 0.07,\n",
      "iteration 1075000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1076000, training loss: 0.05,\n",
      "iteration 1077000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1078000, training loss: 0.05,\n",
      "iteration 1079000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1080000, training loss: 0.13,\n",
      "iteration 1081000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1082000, training loss: 0.12,\n",
      "iteration 1083000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 1084000, training loss: 0.06,\n",
      "iteration 1085000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1086000, training loss: 0.04,\n",
      "iteration 1087000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1088000, training loss: 0.04,\n",
      "iteration 1089000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1090000, training loss: 0.04,\n",
      "iteration 1091000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1092000, training loss: 0.05,\n",
      "iteration 1093000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1094000, training loss: 0.26,\n",
      "iteration 1095000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1096000, training loss: 0.19,\n",
      "iteration 1097000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1098000, training loss: 0.04,\n",
      "iteration 1099000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1100000, training loss: 0.16,\n",
      "iteration 1101000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1102000, training loss: 0.05,\n",
      "iteration 1103000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1104000, training loss: 0.07,\n",
      "iteration 1105000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1106000, training loss: 0.07,\n",
      "iteration 1107000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 1108000, training loss: 0.04,\n",
      "iteration 1109000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1110000, training loss: 0.05,\n",
      "iteration 1111000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.2% 500 way one-shot learning accuracy\n",
      "iteration 1112000, training loss: 0.06,\n",
      "iteration 1113000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1114000, training loss: 0.04,\n",
      "iteration 1115000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1116000, training loss: 0.04,\n",
      "iteration 1117000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 1118000, training loss: 0.04,\n",
      "iteration 1119000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1120000, training loss: 0.04,\n",
      "iteration 1121000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1122000, training loss: 0.06,\n",
      "iteration 1123000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1124000, training loss: 0.04,\n",
      "iteration 1125000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1126000, training loss: 0.06,\n",
      "iteration 1127000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1128000, training loss: 0.04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1129000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1130000, training loss: 0.13,\n",
      "iteration 1131000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1132000, training loss: 0.14,\n",
      "iteration 1133000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1134000, training loss: 0.06,\n",
      "iteration 1135000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1136000, training loss: 0.04,\n",
      "iteration 1137000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1138000, training loss: 0.05,\n",
      "iteration 1139000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 1140000, training loss: 0.04,\n",
      "iteration 1141000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.8% 500 way one-shot learning accuracy\n",
      "iteration 1142000, training loss: 0.09,\n",
      "iteration 1143000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1144000, training loss: 0.04,\n",
      "iteration 1145000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1146000, training loss: 0.04,\n",
      "iteration 1147000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1148000, training loss: 0.04,\n",
      "iteration 1149000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 1150000, training loss: 0.07,\n",
      "iteration 1151000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1152000, training loss: 0.06,\n",
      "iteration 1153000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1154000, training loss: 0.06,\n",
      "iteration 1155000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1156000, training loss: 0.04,\n",
      "iteration 1157000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1158000, training loss: 0.04,\n",
      "iteration 1159000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1160000, training loss: 0.07,\n",
      "iteration 1161000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1162000, training loss: 0.04,\n",
      "iteration 1163000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 1164000, training loss: 0.04,\n",
      "iteration 1165000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 58.0% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 1166000, training loss: 0.05,\n",
      "iteration 1167000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1168000, training loss: 0.04,\n",
      "iteration 1169000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1170000, training loss: 0.16,\n",
      "iteration 1171000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1172000, training loss: 0.05,\n",
      "iteration 1173000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1174000, training loss: 0.08,\n",
      "iteration 1175000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 57.6% 500 way one-shot learning accuracy\n",
      "iteration 1176000, training loss: 0.25,\n",
      "iteration 1177000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1178000, training loss: 0.04,\n",
      "iteration 1179000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1180000, training loss: 0.25,\n",
      "iteration 1181000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1182000, training loss: 0.06,\n",
      "iteration 1183000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1184000, training loss: 0.05,\n",
      "iteration 1185000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 1186000, training loss: 0.04,\n",
      "iteration 1187000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1188000, training loss: 0.04,\n",
      "iteration 1189000, training loss: 0.17,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1190000, training loss: 0.04,\n",
      "iteration 1191000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1192000, training loss: 0.04,\n",
      "iteration 1193000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1194000, training loss: 0.05,\n",
      "iteration 1195000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1196000, training loss: 0.04,\n",
      "iteration 1197000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1198000, training loss: 0.04,\n",
      "iteration 1199000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1200000, training loss: 0.04,\n",
      "iteration 1201000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 58.0% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 1202000, training loss: 0.06,\n",
      "iteration 1203000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.6% 500 way one-shot learning accuracy\n",
      "iteration 1204000, training loss: 0.06,\n",
      "iteration 1205000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1206000, training loss: 0.04,\n",
      "iteration 1207000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1208000, training loss: 0.04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1209000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.4% 500 way one-shot learning accuracy\n",
      "iteration 1210000, training loss: 0.04,\n",
      "iteration 1211000, training loss: 0.23,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1212000, training loss: 0.05,\n",
      "iteration 1213000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1214000, training loss: 0.04,\n",
      "iteration 1215000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1216000, training loss: 0.06,\n",
      "iteration 1217000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1218000, training loss: 0.05,\n",
      "iteration 1219000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1220000, training loss: 0.05,\n",
      "iteration 1221000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1222000, training loss: 0.04,\n",
      "iteration 1223000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1224000, training loss: 0.05,\n",
      "iteration 1225000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1226000, training loss: 0.04,\n",
      "iteration 1227000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1228000, training loss: 0.04,\n",
      "iteration 1229000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1230000, training loss: 0.04,\n",
      "iteration 1231000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1232000, training loss: 0.05,\n",
      "iteration 1233000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1234000, training loss: 0.04,\n",
      "iteration 1235000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1236000, training loss: 0.04,\n",
      "iteration 1237000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1238000, training loss: 0.05,\n",
      "iteration 1239000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1240000, training loss: 0.05,\n",
      "iteration 1241000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1242000, training loss: 0.05,\n",
      "iteration 1243000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1244000, training loss: 0.04,\n",
      "iteration 1245000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1246000, training loss: 0.10,\n",
      "iteration 1247000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1248000, training loss: 0.04,\n",
      "iteration 1249000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1250000, training loss: 0.04,\n",
      "iteration 1251000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1252000, training loss: 0.04,\n",
      "iteration 1253000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 58.0% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 1254000, training loss: 0.04,\n",
      "iteration 1255000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 1256000, training loss: 0.04,\n",
      "iteration 1257000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1258000, training loss: 0.04,\n",
      "iteration 1259000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1260000, training loss: 0.04,\n",
      "iteration 1261000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1262000, training loss: 0.04,\n",
      "iteration 1263000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1264000, training loss: 0.04,\n",
      "iteration 1265000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1266000, training loss: 0.04,\n",
      "iteration 1267000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1268000, training loss: 0.06,\n",
      "iteration 1269000, training loss: 0.17,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1270000, training loss: 0.04,\n",
      "iteration 1271000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1272000, training loss: 0.04,\n",
      "iteration 1273000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1274000, training loss: 0.04,\n",
      "iteration 1275000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1276000, training loss: 0.04,\n",
      "iteration 1277000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 38.0% 500 way one-shot learning accuracy\n",
      "iteration 1278000, training loss: 0.07,\n",
      "iteration 1279000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 1280000, training loss: 0.04,\n",
      "iteration 1281000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1282000, training loss: 0.04,\n",
      "iteration 1283000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.4% 500 way one-shot learning accuracy\n",
      "iteration 1284000, training loss: 0.04,\n",
      "iteration 1285000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1286000, training loss: 0.04,\n",
      "iteration 1287000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1288000, training loss: 0.04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1289000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1290000, training loss: 0.04,\n",
      "iteration 1291000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1292000, training loss: 0.07,\n",
      "iteration 1293000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1294000, training loss: 0.04,\n",
      "iteration 1295000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1296000, training loss: 0.06,\n",
      "iteration 1297000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1298000, training loss: 0.05,\n",
      "iteration 1299000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1300000, training loss: 0.04,\n",
      "iteration 1301000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 1302000, training loss: 0.04,\n",
      "iteration 1303000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1304000, training loss: 0.04,\n",
      "iteration 1305000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1306000, training loss: 0.06,\n",
      "iteration 1307000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1308000, training loss: 0.05,\n",
      "iteration 1309000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1310000, training loss: 0.04,\n",
      "iteration 1311000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1312000, training loss: 0.04,\n",
      "iteration 1313000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 1314000, training loss: 0.04,\n",
      "iteration 1315000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1316000, training loss: 0.04,\n",
      "iteration 1317000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1318000, training loss: 0.04,\n",
      "iteration 1319000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1320000, training loss: 0.04,\n",
      "iteration 1321000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1322000, training loss: 0.04,\n",
      "iteration 1323000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1324000, training loss: 0.04,\n",
      "iteration 1325000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 1326000, training loss: 0.04,\n",
      "iteration 1327000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1328000, training loss: 0.15,\n",
      "iteration 1329000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1330000, training loss: 0.04,\n",
      "iteration 1331000, training loss: 0.19,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 57.2% 500 way one-shot learning accuracy\n",
      "iteration 1332000, training loss: 0.04,\n",
      "iteration 1333000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1334000, training loss: 0.04,\n",
      "iteration 1335000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1336000, training loss: 0.06,\n",
      "iteration 1337000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1338000, training loss: 0.04,\n",
      "iteration 1339000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 1340000, training loss: 0.04,\n",
      "iteration 1341000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1342000, training loss: 0.04,\n",
      "iteration 1343000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1344000, training loss: 0.04,\n",
      "iteration 1345000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1346000, training loss: 0.04,\n",
      "iteration 1347000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1348000, training loss: 0.04,\n",
      "iteration 1349000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.8% 500 way one-shot learning accuracy\n",
      "iteration 1350000, training loss: 0.04,\n",
      "iteration 1351000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1352000, training loss: 0.05,\n",
      "iteration 1353000, training loss: 0.19,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1354000, training loss: 0.04,\n",
      "iteration 1355000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1356000, training loss: 0.04,\n",
      "iteration 1357000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1358000, training loss: 0.05,\n",
      "iteration 1359000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1360000, training loss: 0.04,\n",
      "iteration 1361000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1362000, training loss: 0.04,\n",
      "iteration 1363000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1364000, training loss: 0.04,\n",
      "iteration 1365000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1366000, training loss: 0.05,\n",
      "iteration 1367000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1368000, training loss: 0.13,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1369000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 1370000, training loss: 0.05,\n",
      "iteration 1371000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.6% 500 way one-shot learning accuracy\n",
      "iteration 1372000, training loss: 0.06,\n",
      "iteration 1373000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1374000, training loss: 0.12,\n",
      "iteration 1375000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1376000, training loss: 0.04,\n",
      "iteration 1377000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1378000, training loss: 0.05,\n",
      "iteration 1379000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1380000, training loss: 0.04,\n",
      "iteration 1381000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1382000, training loss: 0.05,\n",
      "iteration 1383000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1384000, training loss: 0.06,\n",
      "iteration 1385000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 1386000, training loss: 0.04,\n",
      "iteration 1387000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1388000, training loss: 0.06,\n",
      "iteration 1389000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1390000, training loss: 0.04,\n",
      "iteration 1391000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1392000, training loss: 0.07,\n",
      "iteration 1393000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1394000, training loss: 0.04,\n",
      "iteration 1395000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 1396000, training loss: 0.09,\n",
      "iteration 1397000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.4% 500 way one-shot learning accuracy\n",
      "iteration 1398000, training loss: 0.05,\n",
      "iteration 1399000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1400000, training loss: 0.06,\n",
      "iteration 1401000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1402000, training loss: 0.04,\n",
      "iteration 1403000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.4% 500 way one-shot learning accuracy\n",
      "iteration 1404000, training loss: 0.04,\n",
      "iteration 1405000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1406000, training loss: 0.04,\n",
      "iteration 1407000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1408000, training loss: 0.15,\n",
      "iteration 1409000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.2% 500 way one-shot learning accuracy\n",
      "iteration 1410000, training loss: 0.04,\n",
      "iteration 1411000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1412000, training loss: 0.04,\n",
      "iteration 1413000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1414000, training loss: 0.04,\n",
      "iteration 1415000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1416000, training loss: 0.06,\n",
      "iteration 1417000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1418000, training loss: 0.08,\n",
      "iteration 1419000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1420000, training loss: 0.17,\n",
      "iteration 1421000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1422000, training loss: 0.05,\n",
      "iteration 1423000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.8% 500 way one-shot learning accuracy\n",
      "iteration 1424000, training loss: 0.04,\n",
      "iteration 1425000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1426000, training loss: 0.10,\n",
      "iteration 1427000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1428000, training loss: 0.04,\n",
      "iteration 1429000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 1430000, training loss: 0.04,\n",
      "iteration 1431000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 1432000, training loss: 0.26,\n",
      "iteration 1433000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1434000, training loss: 0.05,\n",
      "iteration 1435000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 1436000, training loss: 0.04,\n",
      "iteration 1437000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1438000, training loss: 0.05,\n",
      "iteration 1439000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 1440000, training loss: 0.15,\n",
      "iteration 1441000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1442000, training loss: 0.04,\n",
      "iteration 1443000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1444000, training loss: 0.04,\n",
      "iteration 1445000, training loss: 0.16,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1446000, training loss: 0.08,\n",
      "iteration 1447000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1448000, training loss: 0.04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1449000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1450000, training loss: 0.04,\n",
      "iteration 1451000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1452000, training loss: 0.04,\n",
      "iteration 1453000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1454000, training loss: 0.08,\n",
      "iteration 1455000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1456000, training loss: 0.04,\n",
      "iteration 1457000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1458000, training loss: 0.04,\n",
      "iteration 1459000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1460000, training loss: 0.04,\n",
      "iteration 1461000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1462000, training loss: 0.04,\n",
      "iteration 1463000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1464000, training loss: 0.04,\n",
      "iteration 1465000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1466000, training loss: 0.04,\n",
      "iteration 1467000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1468000, training loss: 0.04,\n",
      "iteration 1469000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1470000, training loss: 0.04,\n",
      "iteration 1471000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1472000, training loss: 0.04,\n",
      "iteration 1473000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1474000, training loss: 0.06,\n",
      "iteration 1475000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1476000, training loss: 0.04,\n",
      "iteration 1477000, training loss: 0.29,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1478000, training loss: 0.04,\n",
      "iteration 1479000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1480000, training loss: 0.05,\n",
      "iteration 1481000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1482000, training loss: 0.04,\n",
      "iteration 1483000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.2% 500 way one-shot learning accuracy\n",
      "iteration 1484000, training loss: 0.04,\n",
      "iteration 1485000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1486000, training loss: 0.04,\n",
      "iteration 1487000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1488000, training loss: 0.09,\n",
      "iteration 1489000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1490000, training loss: 0.09,\n",
      "iteration 1491000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1492000, training loss: 0.04,\n",
      "iteration 1493000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1494000, training loss: 0.04,\n",
      "iteration 1495000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1496000, training loss: 0.04,\n",
      "iteration 1497000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.0% 500 way one-shot learning accuracy\n",
      "iteration 1498000, training loss: 0.29,\n",
      "iteration 1499000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1500000, training loss: 0.04,\n",
      "iteration 1501000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1502000, training loss: 0.05,\n",
      "iteration 1503000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1504000, training loss: 0.05,\n",
      "iteration 1505000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1506000, training loss: 0.04,\n",
      "iteration 1507000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1508000, training loss: 0.04,\n",
      "iteration 1509000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1510000, training loss: 0.04,\n",
      "iteration 1511000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1512000, training loss: 0.04,\n",
      "iteration 1513000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1514000, training loss: 0.04,\n",
      "iteration 1515000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1516000, training loss: 0.04,\n",
      "iteration 1517000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.0% 500 way one-shot learning accuracy\n",
      "iteration 1518000, training loss: 0.04,\n",
      "iteration 1519000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 1520000, training loss: 0.05,\n",
      "iteration 1521000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1522000, training loss: 0.04,\n",
      "iteration 1523000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1524000, training loss: 0.04,\n",
      "iteration 1525000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1526000, training loss: 0.04,\n",
      "iteration 1527000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1528000, training loss: 0.04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1529000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 1530000, training loss: 0.16,\n",
      "iteration 1531000, training loss: 0.27,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1532000, training loss: 0.08,\n",
      "iteration 1533000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1534000, training loss: 0.07,\n",
      "iteration 1535000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1536000, training loss: 0.03,\n",
      "iteration 1537000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1538000, training loss: 0.04,\n",
      "iteration 1539000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1540000, training loss: 0.04,\n",
      "iteration 1541000, training loss: 0.25,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1542000, training loss: 0.06,\n",
      "iteration 1543000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1544000, training loss: 0.04,\n",
      "iteration 1545000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1546000, training loss: 0.04,\n",
      "iteration 1547000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 58.4% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 1548000, training loss: 0.04,\n",
      "iteration 1549000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1550000, training loss: 0.06,\n",
      "iteration 1551000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1552000, training loss: 0.04,\n",
      "iteration 1553000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1554000, training loss: 0.04,\n",
      "iteration 1555000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1556000, training loss: 0.10,\n",
      "iteration 1557000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1558000, training loss: 0.04,\n",
      "iteration 1559000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1560000, training loss: 0.04,\n",
      "iteration 1561000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1562000, training loss: 0.08,\n",
      "iteration 1563000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1564000, training loss: 0.16,\n",
      "iteration 1565000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1566000, training loss: 0.04,\n",
      "iteration 1567000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1568000, training loss: 0.06,\n",
      "iteration 1569000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1570000, training loss: 0.04,\n",
      "iteration 1571000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1572000, training loss: 0.07,\n",
      "iteration 1573000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1574000, training loss: 0.04,\n",
      "iteration 1575000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1576000, training loss: 0.04,\n",
      "iteration 1577000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1578000, training loss: 0.04,\n",
      "iteration 1579000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1580000, training loss: 0.04,\n",
      "iteration 1581000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1582000, training loss: 0.04,\n",
      "iteration 1583000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1584000, training loss: 0.04,\n",
      "iteration 1585000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1586000, training loss: 0.14,\n",
      "iteration 1587000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1588000, training loss: 0.05,\n",
      "iteration 1589000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1590000, training loss: 0.04,\n",
      "iteration 1591000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1592000, training loss: 0.04,\n",
      "iteration 1593000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1594000, training loss: 0.05,\n",
      "iteration 1595000, training loss: 0.12,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1596000, training loss: 0.04,\n",
      "iteration 1597000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.6% 500 way one-shot learning accuracy\n",
      "iteration 1598000, training loss: 0.04,\n",
      "iteration 1599000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 1600000, training loss: 0.04,\n",
      "iteration 1601000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.8% 500 way one-shot learning accuracy\n",
      "iteration 1602000, training loss: 0.04,\n",
      "iteration 1603000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1604000, training loss: 0.04,\n",
      "iteration 1605000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1606000, training loss: 0.04,\n",
      "iteration 1607000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1608000, training loss: 0.04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1609000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1610000, training loss: 0.07,\n",
      "iteration 1611000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1612000, training loss: 0.13,\n",
      "iteration 1613000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1614000, training loss: 0.03,\n",
      "iteration 1615000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1616000, training loss: 0.04,\n",
      "iteration 1617000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1618000, training loss: 0.03,\n",
      "iteration 1619000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1620000, training loss: 0.04,\n",
      "iteration 1621000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1622000, training loss: 0.04,\n",
      "iteration 1623000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1624000, training loss: 0.04,\n",
      "iteration 1625000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1626000, training loss: 0.04,\n",
      "iteration 1627000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1628000, training loss: 0.04,\n",
      "iteration 1629000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 1630000, training loss: 0.11,\n",
      "iteration 1631000, training loss: 0.21,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1632000, training loss: 0.04,\n",
      "iteration 1633000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1634000, training loss: 0.04,\n",
      "iteration 1635000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1636000, training loss: 0.04,\n",
      "iteration 1637000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1638000, training loss: 0.04,\n",
      "iteration 1639000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.6% 500 way one-shot learning accuracy\n",
      "iteration 1640000, training loss: 0.05,\n",
      "iteration 1641000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1642000, training loss: 0.04,\n",
      "iteration 1643000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1644000, training loss: 0.04,\n",
      "iteration 1645000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1646000, training loss: 0.04,\n",
      "iteration 1647000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 1648000, training loss: 0.03,\n",
      "iteration 1649000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1650000, training loss: 0.04,\n",
      "iteration 1651000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1652000, training loss: 0.04,\n",
      "iteration 1653000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1654000, training loss: 0.04,\n",
      "iteration 1655000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1656000, training loss: 0.04,\n",
      "iteration 1657000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.8% 500 way one-shot learning accuracy\n",
      "iteration 1658000, training loss: 0.05,\n",
      "iteration 1659000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1660000, training loss: 0.04,\n",
      "iteration 1661000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1662000, training loss: 0.04,\n",
      "iteration 1663000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1664000, training loss: 0.04,\n",
      "iteration 1665000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1666000, training loss: 0.04,\n",
      "iteration 1667000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1668000, training loss: 0.04,\n",
      "iteration 1669000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1670000, training loss: 0.04,\n",
      "iteration 1671000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1672000, training loss: 0.19,\n",
      "iteration 1673000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1674000, training loss: 0.04,\n",
      "iteration 1675000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1676000, training loss: 0.04,\n",
      "iteration 1677000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1678000, training loss: 0.04,\n",
      "iteration 1679000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.8% 500 way one-shot learning accuracy\n",
      "iteration 1680000, training loss: 0.04,\n",
      "iteration 1681000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1682000, training loss: 0.04,\n",
      "iteration 1683000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1684000, training loss: 0.04,\n",
      "iteration 1685000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1686000, training loss: 0.04,\n",
      "iteration 1687000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1688000, training loss: 0.04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1689000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1690000, training loss: 0.05,\n",
      "iteration 1691000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 60.8% 500 way one-shot learning accuracy\n",
      "saving\n",
      "iteration 1692000, training loss: 0.17,\n",
      "iteration 1693000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 57.2% 500 way one-shot learning accuracy\n",
      "iteration 1694000, training loss: 0.04,\n",
      "iteration 1695000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 1696000, training loss: 0.06,\n",
      "iteration 1697000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1698000, training loss: 0.03,\n",
      "iteration 1699000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1700000, training loss: 0.04,\n",
      "iteration 1701000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1702000, training loss: 0.05,\n",
      "iteration 1703000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1704000, training loss: 0.04,\n",
      "iteration 1705000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 1706000, training loss: 0.04,\n",
      "iteration 1707000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1708000, training loss: 0.03,\n",
      "iteration 1709000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1710000, training loss: 0.04,\n",
      "iteration 1711000, training loss: 0.23,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1712000, training loss: 0.03,\n",
      "iteration 1713000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1714000, training loss: 0.04,\n",
      "iteration 1715000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1716000, training loss: 0.03,\n",
      "iteration 1717000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1718000, training loss: 0.03,\n",
      "iteration 1719000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1720000, training loss: 0.08,\n",
      "iteration 1721000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1722000, training loss: 0.04,\n",
      "iteration 1723000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 58.4% 500 way one-shot learning accuracy\n",
      "iteration 1724000, training loss: 0.04,\n",
      "iteration 1725000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1726000, training loss: 0.05,\n",
      "iteration 1727000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1728000, training loss: 0.04,\n",
      "iteration 1729000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1730000, training loss: 0.04,\n",
      "iteration 1731000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1732000, training loss: 0.04,\n",
      "iteration 1733000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 44.4% 500 way one-shot learning accuracy\n",
      "iteration 1734000, training loss: 0.04,\n",
      "iteration 1735000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1736000, training loss: 0.05,\n",
      "iteration 1737000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 1738000, training loss: 0.04,\n",
      "iteration 1739000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1740000, training loss: 0.04,\n",
      "iteration 1741000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 57.2% 500 way one-shot learning accuracy\n",
      "iteration 1742000, training loss: 0.04,\n",
      "iteration 1743000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1744000, training loss: 0.04,\n",
      "iteration 1745000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1746000, training loss: 0.04,\n",
      "iteration 1747000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1748000, training loss: 0.04,\n",
      "iteration 1749000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1750000, training loss: 0.04,\n",
      "iteration 1751000, training loss: 0.15,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1752000, training loss: 0.03,\n",
      "iteration 1753000, training loss: 0.22,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1754000, training loss: 0.08,\n",
      "iteration 1755000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1756000, training loss: 0.05,\n",
      "iteration 1757000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1758000, training loss: 0.03,\n",
      "iteration 1759000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 57.2% 500 way one-shot learning accuracy\n",
      "iteration 1760000, training loss: 0.04,\n",
      "iteration 1761000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1762000, training loss: 0.07,\n",
      "iteration 1763000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1764000, training loss: 0.06,\n",
      "iteration 1765000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1766000, training loss: 0.06,\n",
      "iteration 1767000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1768000, training loss: 0.04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1769000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1770000, training loss: 0.04,\n",
      "iteration 1771000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1772000, training loss: 0.03,\n",
      "iteration 1773000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1774000, training loss: 0.06,\n",
      "iteration 1775000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1776000, training loss: 0.04,\n",
      "iteration 1777000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1778000, training loss: 0.04,\n",
      "iteration 1779000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1780000, training loss: 0.06,\n",
      "iteration 1781000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1782000, training loss: 0.04,\n",
      "iteration 1783000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.6% 500 way one-shot learning accuracy\n",
      "iteration 1784000, training loss: 0.17,\n",
      "iteration 1785000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1786000, training loss: 0.05,\n",
      "iteration 1787000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1788000, training loss: 0.04,\n",
      "iteration 1789000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1790000, training loss: 0.04,\n",
      "iteration 1791000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1792000, training loss: 0.04,\n",
      "iteration 1793000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1794000, training loss: 0.05,\n",
      "iteration 1795000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1796000, training loss: 0.04,\n",
      "iteration 1797000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1798000, training loss: 0.04,\n",
      "iteration 1799000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1800000, training loss: 0.04,\n",
      "iteration 1801000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1802000, training loss: 0.03,\n",
      "iteration 1803000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1804000, training loss: 0.04,\n",
      "iteration 1805000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1806000, training loss: 0.05,\n",
      "iteration 1807000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.6% 500 way one-shot learning accuracy\n",
      "iteration 1808000, training loss: 0.03,\n",
      "iteration 1809000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1810000, training loss: 0.04,\n",
      "iteration 1811000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1812000, training loss: 0.04,\n",
      "iteration 1813000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1814000, training loss: 0.04,\n",
      "iteration 1815000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.6% 500 way one-shot learning accuracy\n",
      "iteration 1816000, training loss: 0.04,\n",
      "iteration 1817000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1818000, training loss: 0.08,\n",
      "iteration 1819000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.8% 500 way one-shot learning accuracy\n",
      "iteration 1820000, training loss: 0.11,\n",
      "iteration 1821000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 1822000, training loss: 0.04,\n",
      "iteration 1823000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.0% 500 way one-shot learning accuracy\n",
      "iteration 1824000, training loss: 0.04,\n",
      "iteration 1825000, training loss: 0.09,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.2% 500 way one-shot learning accuracy\n",
      "iteration 1826000, training loss: 0.09,\n",
      "iteration 1827000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1828000, training loss: 0.04,\n",
      "iteration 1829000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1830000, training loss: 0.04,\n",
      "iteration 1831000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1832000, training loss: 0.07,\n",
      "iteration 1833000, training loss: 0.11,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1834000, training loss: 0.05,\n",
      "iteration 1835000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1836000, training loss: 0.04,\n",
      "iteration 1837000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 1838000, training loss: 0.04,\n",
      "iteration 1839000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1840000, training loss: 0.16,\n",
      "iteration 1841000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.8% 500 way one-shot learning accuracy\n",
      "iteration 1842000, training loss: 0.03,\n",
      "iteration 1843000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 43.2% 500 way one-shot learning accuracy\n",
      "iteration 1844000, training loss: 0.05,\n",
      "iteration 1845000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.4% 500 way one-shot learning accuracy\n",
      "iteration 1846000, training loss: 0.04,\n",
      "iteration 1847000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1848000, training loss: 0.03,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1849000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 1850000, training loss: 0.03,\n",
      "iteration 1851000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1852000, training loss: 0.04,\n",
      "iteration 1853000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1854000, training loss: 0.03,\n",
      "iteration 1855000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1856000, training loss: 0.03,\n",
      "iteration 1857000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1858000, training loss: 0.03,\n",
      "iteration 1859000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1860000, training loss: 0.05,\n",
      "iteration 1861000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1862000, training loss: 0.04,\n",
      "iteration 1863000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.8% 500 way one-shot learning accuracy\n",
      "iteration 1864000, training loss: 0.03,\n",
      "iteration 1865000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1866000, training loss: 0.04,\n",
      "iteration 1867000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1868000, training loss: 0.05,\n",
      "iteration 1869000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1870000, training loss: 0.04,\n",
      "iteration 1871000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.4% 500 way one-shot learning accuracy\n",
      "iteration 1872000, training loss: 0.04,\n",
      "iteration 1873000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1874000, training loss: 0.06,\n",
      "iteration 1875000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1876000, training loss: 0.04,\n",
      "iteration 1877000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1878000, training loss: 0.03,\n",
      "iteration 1879000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1880000, training loss: 0.05,\n",
      "iteration 1881000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1882000, training loss: 0.04,\n",
      "iteration 1883000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.0% 500 way one-shot learning accuracy\n",
      "iteration 1884000, training loss: 0.04,\n",
      "iteration 1885000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1886000, training loss: 0.06,\n",
      "iteration 1887000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.8% 500 way one-shot learning accuracy\n",
      "iteration 1888000, training loss: 0.04,\n",
      "iteration 1889000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1890000, training loss: 0.10,\n",
      "iteration 1891000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1892000, training loss: 0.04,\n",
      "iteration 1893000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.6% 500 way one-shot learning accuracy\n",
      "iteration 1894000, training loss: 0.03,\n",
      "iteration 1895000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1896000, training loss: 0.03,\n",
      "iteration 1897000, training loss: 0.20,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1898000, training loss: 0.03,\n",
      "iteration 1899000, training loss: 0.13,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.6% 500 way one-shot learning accuracy\n",
      "iteration 1900000, training loss: 0.04,\n",
      "iteration 1901000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1902000, training loss: 0.14,\n",
      "iteration 1903000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1904000, training loss: 0.03,\n",
      "iteration 1905000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1906000, training loss: 0.03,\n",
      "iteration 1907000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1908000, training loss: 0.15,\n",
      "iteration 1909000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1910000, training loss: 0.04,\n",
      "iteration 1911000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 42.4% 500 way one-shot learning accuracy\n",
      "iteration 1912000, training loss: 0.03,\n",
      "iteration 1913000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1914000, training loss: 0.04,\n",
      "iteration 1915000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.2% 500 way one-shot learning accuracy\n",
      "iteration 1916000, training loss: 0.03,\n",
      "iteration 1917000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1918000, training loss: 0.03,\n",
      "iteration 1919000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.6% 500 way one-shot learning accuracy\n",
      "iteration 1920000, training loss: 0.04,\n",
      "iteration 1921000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.4% 500 way one-shot learning accuracy\n",
      "iteration 1922000, training loss: 0.05,\n",
      "iteration 1923000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.8% 500 way one-shot learning accuracy\n",
      "iteration 1924000, training loss: 0.04,\n",
      "iteration 1925000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 60.4% 500 way one-shot learning accuracy\n",
      "iteration 1926000, training loss: 0.18,\n",
      "iteration 1927000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.8% 500 way one-shot learning accuracy\n",
      "iteration 1928000, training loss: 0.09,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1929000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1930000, training loss: 0.03,\n",
      "iteration 1931000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.2% 500 way one-shot learning accuracy\n",
      "iteration 1932000, training loss: 0.03,\n",
      "iteration 1933000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1934000, training loss: 0.07,\n",
      "iteration 1935000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1936000, training loss: 0.05,\n",
      "iteration 1937000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1938000, training loss: 0.05,\n",
      "iteration 1939000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.2% 500 way one-shot learning accuracy\n",
      "iteration 1940000, training loss: 0.04,\n",
      "iteration 1941000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.0% 500 way one-shot learning accuracy\n",
      "iteration 1942000, training loss: 0.04,\n",
      "iteration 1943000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 1944000, training loss: 0.04,\n",
      "iteration 1945000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1946000, training loss: 0.15,\n",
      "iteration 1947000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 56.0% 500 way one-shot learning accuracy\n",
      "iteration 1948000, training loss: 0.03,\n",
      "iteration 1949000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1950000, training loss: 0.03,\n",
      "iteration 1951000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 47.2% 500 way one-shot learning accuracy\n",
      "iteration 1952000, training loss: 0.04,\n",
      "iteration 1953000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 46.4% 500 way one-shot learning accuracy\n",
      "iteration 1954000, training loss: 0.04,\n",
      "iteration 1955000, training loss: 0.05,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 55.6% 500 way one-shot learning accuracy\n",
      "iteration 1956000, training loss: 0.04,\n",
      "iteration 1957000, training loss: 0.07,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1958000, training loss: 0.04,\n",
      "iteration 1959000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.8% 500 way one-shot learning accuracy\n",
      "iteration 1960000, training loss: 0.04,\n",
      "iteration 1961000, training loss: 0.10,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 58.4% 500 way one-shot learning accuracy\n",
      "iteration 1962000, training loss: 0.03,\n",
      "iteration 1963000, training loss: 0.08,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 53.6% 500 way one-shot learning accuracy\n",
      "iteration 1964000, training loss: 0.06,\n",
      "iteration 1965000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1966000, training loss: 0.03,\n",
      "iteration 1967000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.8% 500 way one-shot learning accuracy\n",
      "iteration 1968000, training loss: 0.04,\n",
      "iteration 1969000, training loss: 0.14,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 51.2% 500 way one-shot learning accuracy\n",
      "iteration 1970000, training loss: 0.04,\n",
      "iteration 1971000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.6% 500 way one-shot learning accuracy\n",
      "iteration 1972000, training loss: 0.03,\n",
      "iteration 1973000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1974000, training loss: 0.04,\n",
      "iteration 1975000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1976000, training loss: 0.05,\n",
      "iteration 1977000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 59.6% 500 way one-shot learning accuracy\n",
      "iteration 1978000, training loss: 0.11,\n",
      "iteration 1979000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 54.0% 500 way one-shot learning accuracy\n",
      "iteration 1980000, training loss: 0.03,\n",
      "iteration 1981000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1982000, training loss: 0.04,\n",
      "iteration 1983000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 45.6% 500 way one-shot learning accuracy\n",
      "iteration 1984000, training loss: 0.03,\n",
      "iteration 1985000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1986000, training loss: 0.03,\n",
      "iteration 1987000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 49.2% 500 way one-shot learning accuracy\n",
      "iteration 1988000, training loss: 0.03,\n",
      "iteration 1989000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 52.8% 500 way one-shot learning accuracy\n",
      "iteration 1990000, training loss: 0.04,\n",
      "iteration 1991000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.0% 500 way one-shot learning accuracy\n",
      "iteration 1992000, training loss: 0.04,\n",
      "iteration 1993000, training loss: 0.06,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 50.4% 500 way one-shot learning accuracy\n",
      "iteration 1994000, training loss: 0.03,\n",
      "iteration 1995000, training loss: 0.04,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 48.4% 500 way one-shot learning accuracy\n",
      "iteration 1996000, training loss: 0.16,\n",
      "iteration 1997000, training loss: 0.03,\n",
      "Evaluating model on 250 unique 500 way one-shot learning tasks ...\n",
      "Got an average of 57.6% 500 way one-shot learning accuracy\n",
      "iteration 1998000, training loss: 0.03,\n",
      "iteration 1999000, training loss: 0.11,\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "evaluate_every = 2000\n",
    "loss_every=1000\n",
    "batch_size = 32\n",
    "N_way = 500\n",
    "n_val = 250\n",
    "best = 0\n",
    "for i in range(1,2000000):\n",
    "    (inputs,targets)=loader.get_batch(batch_size)\n",
    "    loss=siamese_net.train_on_batch(inputs,targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        val_acc = loader.test_oneshot(siamese_net,N_way,n_val,verbose=True)\n",
    "        if val_acc >= best:\n",
    "            print(\"saving\")\n",
    "            siamese_net.save(file_path+'/weights')\n",
    "            best=val_acc\n",
    "\n",
    "    if i % loss_every == 0:\n",
    "        print(\"iteration {}, training loss: {:.2f},\".format(i,loss))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T11:22:36.583275Z",
     "start_time": "2017-11-27T11:22:36.364266Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_net.load_weights(f\"{file_path}/weights_500_2000000_60\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T04:16:03.898422Z",
     "start_time": "2017-11-17T04:16:00.323Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_2': <keras.layers.core.Dense at 0x7fafe3e61e10>,\n",
       " 'input_1': <keras.engine.topology.InputLayer at 0x7fb058345cf8>,\n",
       " 'input_2': <keras.engine.topology.InputLayer at 0x7fb058345d30>,\n",
       " 'merge_1': <keras.legacy.layers.Merge at 0x7fafe3e87438>,\n",
       " 'sequential_1': <keras.models.Sequential at 0x7fb05dfac630>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = dict((layer.name,layer) for layer in siamese_net.layers)\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model with oneshot tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T14:53:42.849816Z",
     "start_time": "2017-11-27T14:53:42.115808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt8AAADnCAYAAADGvDotAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnVusXdV5/ccxOImNTXwJYDAGQ7BxwYRbQknCPyFVLlLU\nplEfcpHah6rqS5W+tS+tKrUvrapeXlq1Uh9SKVVekodISapKUZpbm+YCISYGYsDcjLkYbAyYO/ic\n/0M6vNYeZ4/zzbXPOZuzm/GT0Gbtvdacc60115r+xhnzm3MLCwsIIYQQQgghrD7r3uwGhBBCCCGE\n8MtC/vEdQgghhBDClMg/vkMIIYQQQpgS+cd3CCGEEEIIUyL/+A4hhBBCCGFK5B/fIYQQQgghTIn8\n4zuEEEIIIYQpkX98hxBCCCGEMCXyj+8QQgghhBCmxNlDdt6wYcPC5s2bz2zPzc2N3a/1e93mapv8\n3pVT1dP6e0Vr+UNXCdXz1O9bj59kdVI9pipj0v2XW09rO1rrG7rfpNst7Zufn8f8/PzyOucU2Lx5\n88L27dvL/Vqfs6HP43Kf36FMWt9qrxK8Es/5co9b6ed3pX5fqffTSrVjXHtefPFFvPrqq2v+ec/4\nPv73jO912zK+Dx/fB/3j+9xzz8WnP/3pM51q3bpfCOfayc4+++yx35911lljt7U8fhK3rfXwe14I\nV5+7Ue6loPVreadPnx7Zb35+fuz++r0+3K0dkPW5evvl6DGE23qM7q9trr4nr7/+OgDgjTfeGHtO\nepzW/9prr42cm54z6+f2q6++OnI8f2c7uK37uXZrOfpJuM326vesj/W88cYbOHXqFGaB7du348/+\n7M/soOoGL30vtO7n3ieuXt4jPa4a/Kp/JLQO6u55rQbt5Q4cS+2n/dmV5cp0/d7tx08+566N+pwr\nrp7q+dP3gb4X9Dz1vaC494yWo+ejx/Wf92984xtj61prZHwfJeP74u9Jxvflj++xnYQQQgghhDAl\nBinfwGi06SJaFxG7/fTTRcL6fRXJVgqWlsdoRiNqPQ+tv4r4GR26CNspeBqNVcreUpG5U+P0GP2s\n1IZqPxe1OxWA+1H1cOehEe369etHvnftfctb3jJSD3/nPdI+pefnztupJNoXnGqyVllYWLDP6dA/\nM5PW53jo81t931p+9Zy14pT61UT7obalwv1VQZ9PvTbu3aPlEFeO4vqKUw1de1vfla2WCFXsXLnr\n1q2bun1qOWR8X1x/xveM76sxvkf5DiGEEEIIYUoMVr7HRZtVxEvUk6VRg4u0q0jale8ibI0sNapx\n7SKufIX7McpzypeLxF15Vb398irlhx4ovfaMINXTRVz0rpGhRsbOi+bOQSNm97tG4tpO136ika5T\n9DSC5vm4vqSKxFlnnTVTSli/rZX3e1Kle+jEqlblyx3vfnceUYd7nyj6e6sS7q6rU5fGtcE9P611\nKU69c/3foc9Vq3Lk2ukUe6L1VEqXq0+VN3fe2jdmhYzvGd/7+2d8X73xPcp3CCGEEEIIU2Kw8t33\ngFaKVqsSplGJ84D129Avt/IttSpaVUSs7W9VW6p6h6JRqda/lCfMKUt6DZ2HkjDa1ywHeg1dOxTt\nAy6SdgrTOK9lf79KlXTtbM1Y4WB7Z83rTSbxrFb3vlX5rt4bQ+t3v1f1V2pw9X2rv7m1z7XcD/du\nqjIyVPfEtU3vzVDF3bWn+r6qnzjl2713WuutrvMs/ZULyPjery/je8b3iuWM71G+QwghhBBCmBIT\neb6db8apCkSjGxdtVVkM9PhWhcx5r5yPUZnUs1kpBc7DqefBKI/XqZotPa6MVjVP93fbGp1rvk71\narkoXu+B89FV99Z5tbTvaLtd39DzVUXAzarW4112hFnAKVH6e5VlZKjS7b4fqlwPVbCr/XW/SuWs\n3hutz2Dloxx3jHvuSOUZ1XeTvhtdNgV9nl2/rxRn3a6yrLg+5uppvT5OIWy5frOkfmd8z/jeJ+P7\n6o3vUb5DCCGEEEKYEoOUb0bFLuKr1BHnuar8Our7cbkoNYqqZqBXSl01u7vVm+miUb1ubn89f73O\nbtb3uDqc367ys2kbXc5UNzu5Uoi0XhcRtypfla/wlVdeGXs8cZGyi2z1vKr8orPEUMXaKWVuf+2b\nrr6hinm136SKulJ50VsVct3fPQPu2ZykbJd1oPLNuneQtnmoeui8nE7Jd+VXChTLc0rZpPnBZy27\nSZ+M7xnfM75Pb3yP8h1CCCGEEMKUGOz5Bmpl60zh4vFSn4+qDy5i1t812nNRjPu98jfq8Xq++rue\nL2n1Mbrv1fOl581Vn1wOzv6+qiTpvXDqhrs2ru1VTlO99y7S1HNUr5VGws6LpcfzOH5ftbPyHapH\nzEXE/f1nRf2em5s78x+3+5+tOEWoen+sttI9tLzl4rzy7r3j3jdDFPrqnCsFuVL1qnepu7fVCpyV\nh7RVUW/1umv5rSuFuu1ZnuOR8R1j98/4nvF9Jcf3KN8hhBBCCCFMicHK97p16xZFwi73Y+vMVRdh\nq69IP533rPKaVh5UF6FXUaBGkUNXtnLbWr7zbY7zHTo/nGuj84JpORq9M9LUvJ2kupbc30XsOgNc\n0XvrlCv+zhW+3Iz9KnuCRtrap9je1157bWz9s8DCwsLYbA2tvuJKuW19zly9Q5XsSX25rs+51Q6H\nKvlaD8t79dVXAQAvv/zyyPHOswp0/V5VSad8uTZXz69r89CsIi6Tg/O/tran6ltVlpRK0XZ5kKsx\nba2T8X1x+7T+jO8Z31difJ+tN0MIIYQQQggzzER5viuvlIsQ1TPlZuQ6n57b1mjI+Zeq8qrIvvI7\nVt4uV16VA9epQk416p9/FYm5Wcfa9iqSdRGrW92M9ap3yuXVdGoIUSVK77lTBpzqwk/1mhG3spVe\np3EK2bQ8xstlbm5upK2tft+hCnZLO5ZznHsfEP5OFWPjxo0AgA0bNgAA3vrWtwIA3va2t418zz7A\nT6otzoOqfU9VJG6zHU8//TQA4PbbbwcAPPjggwCAEydOAOhm9J9zzjln6rryyitHvnvxxRcBdCo6\nv9+5c+dIm7WtLtcwce+m6t3oVD/3nnHvHbftvNb6PqgySrR6xZ2yOGmffbPJ+J7xvf99xvfVG9+j\nfIcQQgghhDAlBuf57kf6lYer1X+nn+pxct6rfrvG/V55JDVyryLq1oim1XvmVvJy6k7lSRunKrkV\npvQY53nSSFGPa82xqhGvRtY6m9hdC+6vK23pvXblOs+bettef/31kfPQ6+ja7yJ351GbZVzfUSrP\npft+uQp5azkPP/wwAOCqq64CAOzduxdAp4DzHrvynKez+mRfcM/ajh07AAAf+tCHAAD79+8HAJw8\neXLks69es5+98MILAIBTp04BAJ544gkAwNGjRwEA27ZtAwB8/OMfH3uOpNUT7pQr9xxXfmDn9VZl\nu9WHrN70qk+4/N/afqXKHrOWyfie8V2Py/i+euN7lO8QQgghhBCmxIrk+SaVv6hSjiqlykWSjkqd\nqFSZChc1tXpeW7MktKopS9Wrkat+r3W5yNYpUc6L5SJF1x49l8pzppGxRqCtfbJa8crlGXU+PY3E\nZ1XxHteXnBJVvRfcta+e/+o50u3q+dUZ8VdccQUA4JJLLgHQebyr91vr+0z313KcuqPPwPbt2wF0\n/u2vfOUrAEY937fccguAzp++efNmAMD5558PoFN8HnvsMQCdJ/ztb387xqFtqbIRVCtgunMm7n3k\n6tNtp8Zqu1w2CPdO13Y4tfL/Ahnff0HG94zvqzm+R/kOIYQQQghhSkykfBOnYGk0orOgW2dTa5TF\n6EK9Z85LpvW5etyMXT1P1z7dr/Iz8nuej+a+rHxIToEbF925fV1EqhFc5SnTyFQVL/VwuTzDLruC\nnpPm1SUuEndeVnd+bvaz64tVhFxd71mgVUlufR7c8UPb0aqQu3L4eeDAAQBd9pD3v//9TfW77yvV\np1LQtK9pTtnvfve7AIAjR44A6JR6oPOJU81nGfQ6apYBltmat7dqK6mU4eoaVc+TU+Sd4qVjh+5f\nKfpVvvGlFP9ZVcczvmd8z/i+euN7lO8QQgghhBCmxEQrXFYKUKV6OE+UmymrUVKVR7ff1qXaQagK\n8XiN5Kt2c/9qxqse73yIqng5VcZF/P3rUKkVboUm54nU43V/FzFqhKzXSmcfa6SquWT1e7dCl+6n\naKTLbZe/1/n42IfUA8btfjtmSQmbm5tbpOxU3sVJFelxdbeUVyle+j1h36f/mX3wve9975LtHqqw\nE6cIuutZqc70abP9APD8888DWPyudL589Tzqu9ipek4BIq4e9/zoe6o1O0qleupzrWOJ8567TBNV\n1pfqrzxrnYzvGd/7x2d8X73xPcp3CCGEEEIIU2Jwnu9+ZKx+Go1smU3AKTtOlVFaZwlX0Y/zWml7\nyFC/YmuWA6fiVBGTiwKXmi3tFCIXobo8nC5/ptbjGOrtJOpRdZ7NofVXvjyX57R15rzz7TrP2SzQ\nmt1gKaVmqeOX6+mu3h+uPGYEYW7soe1Uqj7B9yL7ErOXuGfV+bZ1RUygy3Kiql2VacZl83A+W9Lq\n9Xa+1sq77d5PbgVLxd07p3g7j6dT5qvrMkvPe8b30fIyvi+ux5Hxffj4HuU7hBBCCCGEKTFRthON\nRN2KVa0Rn4tw3fFV/kyNhN2sad2ftCpuWm7VLqe2uKjRrSjm1KZx5VQKj9ZBb5buV9XprrXLD6rH\naR/SPqHHO8+m+uhUgXJKmFMIFLc6GalUoLm5uZn1gw7F9bmh74XW/Z1vt8oeQMWbqz66drcq7625\nsNVL2qqysC8fP34cALBp06Yz+zqvN1Vz1qk+WIdT89y1JVV2ktYMD/o+qBQxl4XAKXnOy+3eP1qv\nKvCVF30WyPg+elzG94zvZCXH9yjfIYQQQgghTInByve4f9VrROZUEZ1lXKkEOivaRaKuPNdmFwk7\ntYU4FaQ18tcZwZOeh/MljvMhurIcbpZ/1eZqZrdTsNy10fpUaXIeLnev3feVv8+hCkLl+ZpFBQzo\nfKD8/2rfId/r762KlFL5AV15qrJccMEFI9+3Kt2t9bpsDpUvW+vZu3cvAOBHP/oRAGDjxo1nfrvw\nwgvH1qVlO2XanaNT/0jl7XSKt7snbgU73c9tuxzKuv/QlSqr6zSrK9mSjO8Z38eVl/F95cf3KN8h\nhBBCCCFMicHK98LCQumhYtTjfIWVl4tUuWadT0iPd+U7r1UVgVYKXWt0VvkNXbu1Ho0K+8c7JUln\nFbsyK5xHynmqiLbHfRKXjcGpAq5vqFetmomv10Ovm8sI0Hr91jLOv9aqCLnjJqXy0Q7NRsB7deON\nNwIALrvsMgC1ol15NIdmdVDlr1KP2V7NlgIAl19+OYButU7n1+W72d1LPa7ysarC5FZ81P0r72jl\ngyVD/yrT6gGv1EmlavdaJ+N7xvc+Gd9Xb3yfrTdDCCGEEEIIM8xE2U408nWRrot2NHpo9VRV37uo\nqpppW0XeVWRf+ZGcr7BSlYZ607TccW1Rj5f+rp5QzYOps4udL82VV2VBqNqnqKKn6LXSclvVVG2H\ni6j1/GY9v/e6dYtXvJtUwW5VzFv7deXNrr7nvb3++usBAFu2bFmyXcynTT+gPiOKU7C1PKrUVLDZ\nV1iPbvPz4osvHjkeAE6dOjVSFn97+eWXR+pmhpTqWjslWverFOLqHaiKk3t/6HHOO0paM89oOc7j\n2vr+IuOen7VOxveM7xnfV398j/IdQgghhBDClJhI+SYaIWv05XxvGllWilZrRD2pD8dF9pVS1+oN\na1X6XATtfIhVRD6uDN2nOrfqXmjEWUWwWq5Gji7S1XN1Xq+q72meT/WGuVnOrlz2fR7nVJlWr9xa\npHrOhnokq+9bFbNJn0tCNfinP/0pAOCZZ54BADz33HMAOtVY+4aqqS+++OLINlVlneHPvnLllVeO\n1Pfd734XAPD8888DADZs2ACgW61S36+6smB/hUu27f777x8pk21hNpRbb70VALB169aRtuvzXilA\nVV+oMjZUz2mlwKvn1Slu2h5tryrgrd7Z/8tkfM/4nvF99cb3KN8hhBBCCCFMiYmU79ZZ+W52cZVj\nVn/XWdEuMtQ8oy7idTNWNepT3KxoFzW58qvZz1VEXfmc+u2vrrVbIcvNRHf7K65P6HGMKPWe8F46\ntcFF4lQFtR1O4dJtHq/etCpyZ4Ss9Y2bdT1Lqtn8/HypJrb+3krr8ZN4I8d9/+yzzwIAvvSlLwEA\nHn/8cQDAOeecA6DLq01Fm5+85+wjO3bsANAp51w5U5/vBx54AADwgQ98AADwyCOPAACeeuopAF2f\noaJNZf2ll14aqY/KfF/5Zs5v1s1j2C+vvvpqAMDu3btHvlelySneToF2uL5RvUeGqo7VO3NoXnM9\nzo09Tq1tvT5rkYzvGd8zvq/++B7lO4QQQgghhCkxWPnu/8teIzSnovSPHfc5ro5+uUN/dxGretdI\n5TF16ooep9HdUPWjUggqD9hSnrjWc9RZ0HouLgtAFcE6lZIRsPOCOm+Xi1TVX6uRrZtlzf37KmL/\nd/Xv6upsGgG7vMaztgLeUpF8a4Rf9ZGhx7n3hpZblc97t2fPHgCdF/vYsWMAuowhP//5zwF0qone\nW5bz9re/HUB3j6k+07t97rnnAgA2b948sj/L1WeByjuVdn5PxZvb9HUDwIkTJ0bOnfuy7v379wPw\n72DntVT0nUSqTA6VMqztckqcluOykWi5lQddcWppldWhGqPWKhnfM773v8/4vnrje5TvEEIIIYQQ\npsRg5bsfAbkIzXmzHM6jpce56MqpN1q+86S5Ge2uHZVKopG/1uv8ga2zvFsVw3F1aETHfTXSZKSo\n+T61Di1fI1Ld30XUQ2fSuwhdvV4uslfPlstuoPfurW99K4DFOZcrBa9S2NYqLe1t9TBOqkiRKltB\nq//XHX/LLbcAAB5++GEAXV++7H9XvqSCzT5GFYW5tXfv3g1gcW5tPmvsWxdddNHI+VxwwQUj+1G9\nZjksn8dTKVcVB+jU9OPHj4+cG4+l6u78reoFde++Sv2r7m3lJ9b9qndgpUy79rrn3fWh6nwq5X+t\nk/E94/tS55DxHSP1LWd8j/IdQgghhBDClBisfC8sLCyKLjQSVjS6qHIhVv65oQqXU95cvcRF3NVs\n5srrNjSPsYvotf6l1BanIjhPlYuonTrhIlp3HKkUI6dIaQSrs6i1fHf+2hdVIag8pzxeZ3UTbc/p\n06dnSv0e0lbXNyplyakkQ9vo+lClZOnzRYWbKjIVZvf79u3bAXQrZTJ7CRVr7eP0gjO/NxVulnve\neeeN1PuOd7wDQNc32adYLvOFA13/Y65wZnJhxhRus+3MjqLXftJ3nVPAFKdwVeqhyzhReb2Je56d\nwu6ULb0+S3ljZ+l5z/ie8X1c2zK+r/z4HuU7hBBCCCGEKTFRnu8qyqp8cZXH00WWrZHxcn9vrbd1\ntrOrv/ILaUTsPGZLzYau2lipBpVn0UWwVXYBRWdNO88a0VnUWq5eGy2vwnnC9Hj1oFXlzBoLCwuD\n296qFLUq0u64oQq7blPNePLJJwEA99xzz0h76b1mrmxmH+G9Vm/37bffDqDLkqL+6W3bto2cH9Xo\nkydPAugUce3rRPsw66WaDXT9kco2s5xQVX/00UcBdCtb3nzzzQCAq666auw1Uqp70oq+F4ZmK6my\nqBCX/aDyuKry5t5v1fWYNc83kPE94/vi3zO+r/z4HuU7hBBCCCGEKTGR8q1UkSNRL9lQj1a17dQR\ntzpRhfM3KW4GvUNzSRLnt9J6qtnR466r816pMqSKzbgVnPptd0pTlV1A99d6Xd5RorOXnU/PzYRX\nL5ce59Rb9iU9zmVbqLI5zAJD29yqOC23nqHojPkvfvGLAIAf/OAHADqPtvZh3luqK1u2bAHQeb0v\n+99sKAcPHgTQebWpgBMq58xWQkVds5ZozlpeFx7Hvsjy+75DHvv0008D6FRxlqF1PfbYYwCASy+9\ndOTcWtXCSsF2x1VeUd2fLKUC9vevFG59XlvfvVVWFJeFYZbJ+J7xXc8t4/vyx/fZfzOEEEIIIYQw\nIyxL+a4iVVJFwFX+S7eSltvWyLLy91Uz3N0saKWKiFtn0isuUnY5K/vtdOeubXBROSPBKiOFi2zd\n70RnH1fX3l0j9WapsqYRsVPsnLrD49Sb5iJ9ot61pc5hLTI3Nzfx7P1q/9bsKBWVoqTto8J92223\nAejuMbOMaF+hX5qfvKf83LFjB4AuK8njjz8OoFNP2CeYgYQZRq699loAwKFDhwB0Sjj7GD+pVtPj\nzfK0b/bPkRlXWIbm+WaGFJah+XArT3XlR3VKeKUU6Ypyrn6if81oVaz1eFeu1qv7uffMLD3jjozv\no2R8z/i+kuN7lO8QQgghhBCmxER5vkmrEqbHVp4m970rT6Me57+r/Hga5XC7ini1PRrNabTk2uUi\neqcCVb7HPtWMbadO6Cxi5+l0q4ipF0vbo5G3WznLza7W/XQ2teZGZnv4PevXdjkljehKWG4FMbbT\nrZS11un3sUrtGPo+aFYICuWrVfEmvAeXXHIJAGDfvn0j21S4dRW4fj7tceWzj9ELrko5+wx/54qa\nDz30EADg3nvvHalPlW/3DPb7FH9jf6Narv2QPncq4fSTax1OFaw80G5FOFL5YTUvMXH3vFIAFfee\ncn103F8Z+t9XivuskPHdk/E94/tKju9RvkMIIYQQQpgSg5Xvubk5G6U4FUD3q1Ypcv4gjbIqf5Lu\n56K/ystWKXvOb1QpAK2eNYcqAKQfXaoqpzOxnYqgZVWqp9tPo3+NfHU/d46kypnq7jUjU70eGtG6\ne6jluUiY23qeOnt6VlhYWLD33m0PpXr+nKpYlVepn/RYM58383bT+33hhRcC6HJlM1sJ7yWzjWjf\nUrWFfYHlM684V7jkNpV1zR/O73k+u3fvHmnnuBUIN23aBKDL983+qqtpMruJ9l+lUprd/m6bVBkm\n9F1evdOH/lXEjSXV99U7flY93xnfF5PxPeP7aozvUb5DCCGEEEKYEsta4VJxuSFdFOWiMeIiS5dz\nUf1LVWTrIutK6VM06qtUJOdvdD5Ircf9Pu76Ow+na4v7Xu9hlZNUr4l6rNQHp31C84m6e0/Uf6cR\nsJ6XXivnF9R2qOdMcZ45bees0O8XK6XytXpA3e+VclSpsoRZSR588EEAXR/g80vfHz+pdGvWEf0k\n6illucx2wm1d6ZLb6v0mVKt/93d/FwCwa9euM7+pQqzPmVs90+XTJU6tdHl2q/7v3iPuU3Fec+IU\nLae+VsdVKmeVf3yWyPg+Ssb3jozvKze+z9a/BEIIIYQQQphhJlK+GS20Rh0uqnFRlVttaegs6krl\nUDRaI3oeGsW1ZoFQdYho1FXNvq48bH3Uq6Xb2tYqS4Heg0pVqPIC6/6qLtBL5dpPdFa1m0Fe9THd\n30XOzkPmFML++cyaH3SoUt2qTE96HSo1s2on/c5UtI8dOwbA91XFvde0HXw/8nd6xvfu3Qug82yz\nfnrPWT4Vcl1hk+0n/b5b+XM1ZzjVfOfL1XJJ5cHU/ZTWe++eK9Lq2SaVGlv1Jb2+bozq941Ze94z\nvmd8d79nfF+58T3KdwghhBBCCFNiomwnrftUEVzlQ3J1VqqMK1+P16inVaVxkWsVESsuD6nzGWo9\nkygqTl2ovJUusnWqh/pfK2+la9e4FaSWOh9th67wpxE3j9eczk5Rq/L9Vl6xWct6spSHtdUD7rZb\n1VNlUkWd31OB/tznPgegU3/ZB1Sxdtv8ZI5sHq+KmcvzTQVbs5voapNu9cnDhw8DGJ9/3PlNeSx9\n5dW7qnqXumte5el2nlKX1URVxUoBr7zg7jwrL7mrT8+veq+uVTK+Z3zv75/xffT8VnJ8j/IdQggh\nhBDClBikfM/NzY1EY5P6+dRbRVQtcZFiNYNXt11k3apKVPVVHtHKR1W1s5ot3aIculm+rVH20Ci8\nUpa0XU4Rcz4652Vziph6yfipqqJTCvX7StHT/fn9+vXrZ8oDOjc316woO7TvtZbjVMyhx2s7+P3V\nV18NoMuFzXvK/N5Uqp2PuvJJK6qI63uQfdFlUeEn1ZUXXngBAPDss88uqsu1kXVorvJWhvZd99y3\nejFJpVgT50d2z3OVv7i1zw3tq2uRjO8Z31vJ+L788T3KdwghhBBCCFNiRTzfLmKsZvc6X02lHjif\nThUlVRHypAreUJXD+Rgrv2BrfeP8U87X5rxW7rgqwlXctXJRPb1ZGrlrn3JKmt4jNwO/NQLWe6Pe\nMXrAXF/TcqrrvdZYWFiwirVTfKr+2ZrVwB3nZtJX5Wm7mE2E3umvfvWrAIA/+qM/AgBcddVVAIZ7\nRolTc3S79Ty4zZU5n3vuOQCjPkTX/3kss50Qbqun0bW99R3q8v5qO1279R3uPNaVb1a3nTJYZeao\nVgzU90//+1lTv6vvMr4vTcb3jO8tRPkOIYQQQghhSgxWvhcWFhatNKVUqgHRlaJUdWn1ilZKGKki\n2tbZ2JXHy0W+k3rWqvPSaLEfDbpzdCvdVVE7cd4tpwS5e1dlLSBOXXGzlzUSde1ipgoqgFVk7VZb\nc/dq3HWbJSUMaH8uHK1K9ND6W+tzzwczfnz+858HANx///0AgL/7u78DAPzJn/wJAGDPnj1Llq/1\n6H6t3lN3PTS7yU9+8hMAXXaUTZs2LdpX/eXaL/nc0PPdmi3EnVv1znJZTbQ8t11lU6jeI1U2k+p8\nnSLf+heBWSHje8b3fpsyvq/e+B7lO4QQQgghhCkxkefbzSzVf/E7n5zDqRWt0dWkSlpVrlMAnN/I\nRYvEfe9Uqko9Wer6uFm57hq3esWIi6CrmeF6HCNNRrpVX3LXmn2zNauB5gnVFatcO9Q7qlR5Q2eR\n6rmZ1BupVEpQ6/NdceeddwIAHnjgAQDARz7ykZH6//Iv/xIA8Md//McAOg94df7aDqemVPC4H/7w\nhwCAAwcOAOj6Jj3rVHeArj9WWUT4uypLQ6lUxUr9a1XGXDnVO7r1vVQp1ZVCPmt/zXJkfO/I+J7x\nfTXH9yhGQdE4AAAgAElEQVTfIYQQQgghTImJPN86g16jIRd9ERdRapREKn+Olut8Oc4PWeF8Va1K\noG63zuCvcuS6XJR9Kk9X9bu2SXG+PefxdCqJ3ns9Z83XqdkZ3LXg91quRtCTZmfQejTiJ1UkvVaZ\nn59vntFesdz9K4Wp8pBq+x966CEAXd84cuQIAOAzn/kMAOBb3/oWAOBP//RPAQB/9Vd/BaDLD+6g\nj/rgwYMAur5w3XXXAehUl4qf/exnAIB77rkHQKd0s28yDzk/gS5/N/3srMsp3u4d5u5RpUhXWVIq\njzapsp649rS2v3pna/vcc6uK2jglbZZ83xnfM74v1daM7ys3vkf5DiGEEEIIYUoMVr7XrVvXPKuY\nDJ3tr8c5P1N13HJ9eK3+JlJF5K59LuKu/IfVfuN+c2qGRni6v6u79do7xavyYA4513G4CJa4lcBc\nxO/6oJvJr8xanu8+QxXvoaok0ed9aF9rbcc73vEOAMDevXsBAKdOnQIAfP3rXwcAXH755QCAu+++\nGwDw4x//GMBi7zfb8eSTTwIAvvzlLwMA7r33XgDAtddeCwA4//zzAQC7d+9esr1PPPEEAODnP/85\ngE7xJkt5vql881w2bNgw0kbN871169aRMl2+6tZ7544nrce35vmusphUx5PqvTJUMZ+1v3CRjO+L\n6yEZ3zO+r+T4HuU7hBBCCCGEKTFY+e7jPJmVR5RUkaeieS4rH1IVzUwK63G5IFs9qlWE71QbPX4p\n/6Sb0V3lrXXRfJU/10V+rvzqntEL1hpBE5397CJ+9qW+etivl/tp5Ou8aHo9qCi6VdnWOv28pcuZ\nlT+OoUq6Hue2q+9ZH+/5RRddBKBTmrly5De/+U0AwE033QSgW1lSoTf7r//6rwEAjz/+OADghhtu\nANCp0d///vcBALt27QKwuC9wP2ZhYfvZh9hXl/LG0m/OHODspyybZfF7Kt/VO41M+g5199q9RxTn\nUXXK1lDlu1K2q/0qRXwWyfie8T3j++qN77P1L4EQQgghhBBmmImynbgZ7lUEqr6cSu1ojZyd30ij\nOZ3FXSluLnqr8oNWtM52Jnqdndoy7jpWni63/1JlAovVt8qrWZ2Tu8eax7NCZ7zzOG67e6l90tXr\nlLXW69lXkmeB+fn5RdeuUilI5Q+sFB9X7rg29ver+rgqW5s3bwbQqcZUSR5++GEAwK233jqyP8un\nmvyFL3wBAHDo0KGR/c8991wAwB133AGg83J/+MMfBtB5wFneI488AgA4fvz4SDuq3Lh9HzfVeZ6T\nvpPpASe68ptTvDTThbtX+hw55cv5+h2urxD37nfv2tZ6dT99X2hfnnUyvmd8BzK+T2N8j/IdQggh\nhBDClJhI+a6iDeIi1daoiAz1gjqfkFNDFI36KiXOtc+pRG5GcOWvrK7DuEjb1e1WhNLjtG4XEQ+d\n7ezQFfq0XufB0nZrLln1hurx6vFyXjK2Q9XISsWpnpW1CFUwd2+X67msMmpU5WkGD7aDea+dAqbb\nzBqiq7DRN+36GO/ptm3bAAB79uwB0CnXzHZywQUXjLTr9ttvBwB8/OMfB9Ap6Pfff/9Iudo3tf6l\nVqfctGnT2HNVzzezolRe7CoDhqqPrdlD9JxaPeDV89bq/XZ+ZuLeG47qfbXWyfie8X2ptmd8X7nx\nPcp3CCGEEEIIU2Kw8j03N7doprmbfa/Rhc4s7ZfZ/yTO01X5+1w0qJ5Nh/MtVsdVPqrW2dGtntXW\n7f53rg2ViuDuqZbjVo5SPyBx95K0rpzllC03U9ydl4tgK5+ji4jHKYaz5PkeR6VAaf+tvN96nFI9\nf3rvXPkK1Y2TJ08C6BRwKtFavlPWPvCBDwAAvvjFLwLoFG5mO2E9zAPOT/L8888DAE6cODFSrvZ5\nfe+Og55utkHfRW9729tGPls939VfI9w1qt47Vd9w7XEqq+ubrd7vqo9WfyEY936bpec947sn43vG\nd2U543uU7xBCCCGEEKbEIOV7YWFhJPuBRrjO90efIXE5ISvly0WKrX6bymOqviONeqrostpW9aVS\naaootvKyLrUPz1UjxcrfV80s13OrMlpohOquiZvdTKosCy5idmqG9nFVg5x64WZTz5L6RVwUX6mD\n1X5OTRiqjPN4ZgVx99YpR7y3jz76KICuD2hOWJb3yiuvjG3Hu971LgDAe97znpFy6f3+6U9/CgD4\n2Mc+BqDzerOcp556aqR8XZWyUqn66LvWvcucmq75fFv9vkSfI32+hr47q7zCVf7uVob6fJ2ndqiP\ndy2R8T3je8b36Y3vUb5DCCGEEEKYEhOtcNma47GKVJ3KoVGX8/VUqoOi5SvO59QSgfaP1/a3RrSK\nq6fKVTvuOrh9W/NYakStbWz1mmmkWeXHra65XmvNfKH7udnNqoa6lbf0vKj66AqCPC9VFF3fW4ss\nLCws+QwP9e0OqRdo9+W2KvEKM4IcOXIEAHDOOecA6PJzb9myBUDXJ5599tmx7eD+XAnzb//2bwF0\nubb//M//HADwqU99aqRewowjqiDqs6V9adx5ujK0v1b+29a81dW9bX3X6f66Xb2fXPk6hqzUebm/\nwvxfyPed8T3ju7Yx4/vKj+9RvkMIIYQQQpgSE+X51qhB/Tb6u0Yv/bL6ODWhipRd1NQasasvSKO3\n1jylQ/N5Vn5Ffs/oSmdzt3jUKuWIaOTYelyr2lmpC24VRTd72mU9aG2ni9wV59/T9lb3dFbz/k7C\npIo3cc+5lq/7u3Lc/vz+hRdeANB5ramA05vNlSlVVdbyPvGJTwDo7vGtt94KANi/f//I+Wh7uCpl\n9Z5wfb5/ndTr6f5q4LyarR7qoX9taFXedH/nOXXtrFRGV79+TnodNC/6rD3vGd8Xk/G9I+P7yo3v\nUb5DCCGEEEKYEoOV7/n5+RXz+blIdrneURfVOc+Zq7919TT3feVH1OMclXql+/UZuvKSi5Bdm4eq\nHdpWlx2hUuh0Pzcbusoj6hQ1vZbOK1b1AVUiZ80T2r+f7l7rZ6tCNKmqsVQb+/u7vkXo1aYHmytR\nMm83fX7/9E//BAD4/d///SXbsWvXLgDA5z73OQC1osZ260qV1XuD37NP9rNSONXQ5b912+4dVr2j\nHe45qRSzST3cldqoVPVWWRb+r5DxPeN7vw0Z31dvfI/yHUIIIYQQwpQYrHyvW7eunPmq0YLOEq5W\nKXKKmlvtqN+2ceUorV6vVp9iq//J5Ultra/abylalRu95lWE6vKJtqoCikagzm9X5Q1Vhs44d8fp\n+RK9TjyuUhjWOuOui+u3rSvGtT431QzySVVMouXzXtHj/e1vfxtA5/3+5Cc/uWS9pHqvKNrntX3a\nfnrPx2UuqVZwU8WGK2E6v6ljub87KuW5VeluVehcva0qbFXv0L7wZpPxPeN7//eM7xg5fiXH99l6\nM4QQQgghhDDDTJTnuzVS0/2WWpltHC76UYWIVKsauZWsNPpy+TyJi2irSNmdF3HtVtx1WWpfpYpY\nW1XMSfPmDvWO6UpSes+q/SoP6FDPqvN4OT9iq5K21hh3XSqVoWLotXCrnrm+2Vr+k08+CaDLHXvH\nHXcAAA4dOgQAuOKKK0b2P3jwIIDu/UOPOPN5T5rDfePGjQBqL2vlu3bfjYP7sW5d1bNS91qVaKdy\nVs9H5e0emj+4olIp3UqBLSrxrD37Gd8zvlflu/pIxveaKN8hhBBCCCFMiYmynVQrUmlUNamHq1pt\nqfLxDPXbtaopVd5dp444f5PzUVXRXOXXGleGiyBdm/Q4d01deeqDW2p1vv7vzhvGT7fan/p3XV90\n7a0UAC3HqSnuPObn52fK/72wsLDo+W71Wg/1MraqB5Xq0KpK0DPNe7Znzx4AwNatW0eOe/zxxwEA\nX/7ylwF0SveNN94IALj22msBALt37wbQrYzp1GRl+/btI+2orq+utrbUe87lnWV/1Nzlre+gobR6\nxFu9m1U+4En/OlONWUqV1WHWyPie8X0cGd9XfnyP8h1CCCGEEMKUmMjzTap/4Wt0opEuFRydae9m\n0lZ+IG2XRmUa/bgI20X+SrVSFlfOe/nllwF0eYVVbeJ25ad0vqSlImkXPVfnqPtX/rrK06Xt0Rnh\nGqm2+u7cKmxuJS+tX3Gru7mIm9+zLyvj1JNZUsX6bW31Iro+Vx1XzXR3fc15Tat6LrroIgDANddc\nAwDYt28fAODRRx8FALzyyisj5etz+73vfQ8A8MMf/hBA5xG/4YYbAABXXnklgM4b/ra3vW1se6i0\n833injX2MfXE9sutFC5uswwe61Q9p2Q5L6T7XRnqyXb1DC2/VW2slPhqnsEs/XXLkfE943vG99Ub\n36N8hxBCCCGEMCWWpXwrLnpy+S9blTDi9q+itipCdmjE66JEtz+9oVxBj8cxumLEvG3btrHtZn2M\n1jSaG3I9XR5QohGpi871mrrjq3I0Yqwi28pTVnk0tV3qhdX2tra/mpnPT2bUmDQjxpvF/Py8nb1P\nWn22lSJVPY9DPeFVfXwu6fWmUk0P9/HjxwF09+zkyZMAgKNHj458z8+HHnoIQJct5cILLwQA3Hzz\nzQCAd73rXSPfM8c23xMXX3zxSPnE9Wn2qT5Usp1PVPst2+CU7pVWdCc9fqivf2g9ri+2jhG/DGR8\nz/ie8X20PcsZ36N8hxBCCCGEMCVWRfluzZ/p/DwaETrPVqXEMRphOYxQtRy3ulvluWpVPTTKYn3M\nhuD8ks5/6SL0pSL9KjJ2ba3USacuVp7Tqn30ydFrNdSD6SJ4h5vhXuWubVVXZsnnTRYWFnD69Gmr\nwCiV13tc+UN+b72WlRLvfqeHk++Jl156CQBw6aWXAui82fv37wfQZT/h87xhwwYAnfr8zDPPAAC+\n8pWvAABuu+02AMD73vc+AJ03/LzzzgPQecaZXcU936q4j+ubrt/yXch3T+vz2voctz6nVVYEV+6k\nuLFHsyoMrXcWn+tJyfg+nozvi8uv2pfxPcp3CCGEEEIIU2NZK1xqpKYRpu7vtonz7aiPxs3oraKj\nVn9TNct6aJTkyuF5OQVAr6uW5yL3/vm4NjuVwqmCzitVleci08prpVTlu4heVZqh/kR3r3U2NFUY\np1bMqkI27n60qhPu+6oPTeoVHap089wOHz4MADh27BiATplm9gK+h7giJlUbZkP56Ec/CgC46667\nAABPP/30SD1U5OgZ//d//3cAnVJOTyizr1AJf+KJJ0bazfeAU/T6/6/vMJcNoZ+fdhxOkWpVsFvV\nwyoLQrXdqkC1elqXy6w+70DG94zvGd+nMb5H+Q4hhBBCCGFK5B/fIYQQQgghTIlBtpOFhV8sNd26\nVKemj6lS+eifX1TSX+rPL/36CNNo8c+7rcu+ti7aofu5NDytf7Jt/ZPP0D8RjzvG7evO3f3JsLpm\nDvfnarcc9tD2K/qnRh6nyfOrFEyO6s9a/T+lzsqfpPm8t05OIa0TsarjlKF9rPrzNydYPvDAAyPl\nc3vnzp0AuhSEb3/72wEAL774IgBg48aNADrbCO0lXHaei/BwwuZ9990HoOtzzz777Ei7OEGLKQm5\n2I9LUTauT+qfvBWWpQv+VPaNVltG6wSs6riKoRMknZXBvW+GTihdKbvKm0nG94zvGd/Hsxrje5Tv\nEEIIIYQQpsQg5XtubumlM12kyO91mVWNJjT60EjZTdSolDQXybvI10Xcen7VJAYt10VxWj5pnVhW\nLYIyru3VtXdpkKpov1Uhq1IWEZcs3+1fRdBDJ1a5a+vUDO1DqgC88cYbM6WSnT59ulRLXDoqxfWx\n6nj93k2qaYXlUKn+7Gc/CwDYsmULgE6R5mI5P/rRjwB0avE555wDALjkkksAdArcddddB6BbROeR\nRx4BAHzwgx8E0C3KwYmXr7766tjz5IRLKuB33HEHgMXp8cYtecy2sK2u/1NlJ06pcpPvtM1DleDq\nfeMmyy2XVkW7al9VXv/3WXneM75nfM/4Pr7c1Rjfo3yHEEIIIYQwJSZKNeiUJxeVcD+NcjSdi/qM\nJsUpaVV7K4VPt52HS8tz7XPRoYuUHZOkyaoiZZdSp3VhAlcet13E69qnEaaeM8vTZWuVoepF5RFz\nfkVXX6tnbi0wPz+P11577YynUhn6nLamJCOtSnprO3Q/qsNc/p2KNZ+/U6dOAQAefvhhAMDBgwcB\nAPfccw8A4Gc/+xkA4LnnngMA7N27F0DnAb/ssssAdAr7hz/8YQDdojtUvvV9yj5yzTXXjOzH+pd6\nVlU1dM8ff+cS2O65qfpz9Xv1vdvPvfta1UPXJ/T909quyp/s9p9FMr5nfM/4vvrj++z8SyCEEEII\nIYQZZ3C2k4WFhWbPlyblZ7J5fq9RjX5fKVsaZbisAK3erSpqqr6vokJSJf13fqJJ6quSyLvZx4qq\nF3rv3Uzx6loQF9G6a+H6iJ6Xq7fVu6n3xqk5rt3ajlnKdgJ0zyxQe7aVlXrOHKrQOVw7VTHjJ7OY\ncJEdLn5DTzezkNCL/eMf/xgA8I1vfAMAcP/99wMA3vnOd460c/fu3QCAEydOAOgUcXcefB+yXir1\nt99+O4BOEe8/4/x/+sH5TtZrzswt7J/9+9xvE6m8la2e6OV6NJ1SVn269lR9bmjfbv19LZLxfenv\nM753ZHxf/vge5TuEEEIIIYQpMZHnWyNZjehUwXEzRqsox6HRTrVMbOXnIS6KdMvguvPS37Xd+nul\n1lSRuTsOqKPyqm1VROv2bz0X5xussi+476s8oNXM8Spi1ki91fOq7ZwF5ufnzyyhDixWQyovpPu9\nVfWs+mRVXqXWqI/QtZN9k2oxFXFmO7nhhhsAAD/5yU8AALfddhsA4Jvf/ObIcfSWP//882Pb5+rn\nddyzZw8AYPv27QC6fORU4oFuyXsq3y6TA9X0l156CUC3fHKlVFeqYqviNPS4ygs+KSv1VxjH3NzS\nGUTWIhnflz4v/V3brb9nfM/4Po4o3yGEEEIIIUyJwcr3/Pz8omhGoyJGN605J/tljyuXaLTl8nW6\neqpoxnm1iEbI6mlrnek6VB3SdruIX/cfR7WyVaUWqhrQGklqveqZalXYXLuHZkFoVR1dpF4pZlVE\nPQvMz8/jpZdeKrMfVNfWbbcqYZWy3ZpXWOunOky1WM+r8pJzhUyqxvR0M083s6TcddddAIDvfOc7\nABZ7vfU8nSrEZ4j5yKleM8sK0OUQf/rpp0fOUa/ZO97xDgDA4cOHASzu51pn63Op59Ki3o07rpVW\n5c6V7675UCV/1tRtR8b3jO/9cjK+j7KS43uU7xBCCCGEEKbEYOW7/y/+KipyEXFrFFQpUC6ac9Gd\n825p1gN3nFsxy+3v2tv6fVVPy/6tHi2N/Cr/nqLnrpGlUuUBrb539etxVT5TF/FW11hVGFL5A2dp\nhcuFhQW89tprzb6+yvOo309anrvmrWqF3mMq2JUSR6gq33fffQA637Qq6VS49+/fDwB48sknAQDH\njx8HUPsftf1OGeOqlkCnijMzxRNPPAGgy5TCfsvc5JW630p1r50CV/WN6nmsrple26FZUlrHKten\nFxZmZ4VLIOP7kHpce1u/r+pp2T/j++yO71G+QwghhBBCmBITZTshGl20esAqb1aVt9PN8K1mwlbt\n0Ei7mm3tzruacazn6aI3ra8qb5zPSc9R8/mqGqAZIPTcXH7NKpJkvZUX1N0T4lSVVs+Wy3Ch5eh+\n7h5pOZVP7/Tp0zOjhNHzTVy/199J6/PvnqOq32t5lSLlfme2kKuvvrqpnmeeeWbk+7e85S0AFq9Q\nyWtHZZ2K+Pve9z4AwOWXXz7SPgf7GNVqZkuhv5vqNtCtvkmVnX50+sLf//73j5xbaz7bocrvchXt\nikkVL5f/2L27q6wJrX/dmUUyvmd8z/i+euN7lO8QQgghhBCmxOAVLufn58tVxipFy6kJLp+oUy+q\nyLnycFWRslvpS9H6Kg+aHqe0Rk7quxrnnWtV1fTYasa1Rthanm5rO1wfIs7jpffCHV95PrUe7bua\nH9kdp5FzdT6TKn1vBvPzv8jzXfl1K++mo1UtrJ7b6n2jx+n33/rWtwAAV111FYDFCjjhvaaC7foI\nlXDm99b2MtPIvn37RvZ3MH/4kSNHAHRKPdvT/+vEQw89BKDzeDMn+QUXXDBSpuunrX+9mFTprbIW\nVOVUCnr1Tq3O2ylkrb58V98skPE94zvJ+L7643uU7xBCCCGEEKbEYM/36dOny1ySbgZslTtSI1OX\nd9PNvGW2Ac70JxrFaXTiVrbS83Czol25k85i1vJ5XlWkP+66O48j28JVzCoPlEaO+llFspXKUHmu\nXB8b+juvpeJUHtdXWY5rt1MCZgl6viu1sjWnqm673LBO+arqGQqf+6NHjwIA/vVf/xUA8KlPfQoA\nsHPnTgBd/m7ingE9n3POOWfk+1OnTgHoPOBUpYl7PzA7ChV3tveyyy5bVO+tt94KoFO6t23bBqDL\nvEKVnG159tlnR9rirnXltdT9lFbPZqtyVHlBl9tet1+lrrbWu1bJ+J7xfdxnxvfRdq/E+D57/yII\nIYQQQghhRpnI860Rq5sV7XxFehyjs349gPeWujyezoPqvGZEoye2x0XCLjJv9f2568LvGXW5vKSK\naw9Qz0J2qoHz77XO9Nbvq1nOGplWnrHqWldKG+85z1+PqzxcTmnQFQXHneesqGILC7/I862KU+XJ\nrHyxTn2oPNrVdXN9bdx59X/fsGEDAODAgQMAOrV4+/btALqVJOkJpwKt5bkV8/j9hRdeOFK+Q/v+\nTTfdBAB47LHHACz2irOdQOf1fvXVVwF0yjbbcvDgwZG6VBnTc6qUola/q/N0Dl010L1Tq/dJtdJe\n6/lW+w1VQ9cSGd8x9jwzvmd8X43xPcp3CCGEEEIIU2KQ8j03NzcSJWq0o6sCtUZJLmIdV3+/XOcR\n1ZmqlYfURSqqmmi0uNQs5H47HJpjV/fXqNZF6Lo9rt4qeq9WvKo8oK2+31aFidfEebi0D2ikymvH\nT1VjnCLmzl89ZixPI2HiIvp169atuHd5tZifn8fLL7/cvH+r4q37t2Ylcb+790xrOVSS2Vd4T3nu\nzJ1N7zW93Bs3bgSw+P2g70F+UnG76KKLlmy/Pr/M1c3VK6m8j1PQtL9S6d61axeAzgvO5505w4dm\nJXC4ctxx1TvSledorbdStN3+1Tt3XJaEWflLV8b3jO96XMb31Rvfo3yHEEIIIYQwJSbyfDu/kPte\nfUdu1q+LeCtPlcvb2eovrFawUs+a8zdVs6Gr3JrVDGE9vsVP6DxWVd0u8m1VO7ScSkHTclzE6cpt\n9XC5SNr1GT1/bad6ylz7+rOnZ0UJm58fn+fbeS9VQary4Faqi1OkKi+mq8fdS3qwmZebfmkqzFSe\nuf3iiy8CAM4///wl69X6qZQzi4rbT2EmEirvbA+hz7vfdvZLZkShr51q/iOPPAIAePzxxwF0ucf1\nWum9VYb6/if1QLs+6Lzc1ftg6HvFvQddRoqhiv1aIOM7xtab8T3j+2qM71G+QwghhBBCmBKD83wv\nLCwsUqRIFYGOK2sc6rtxuSe1HC2PUYvOanbRzjj/Tst5uSirypc6NDekW01qqe3KV1rlZnXb+r0r\nr/KOaUSpPr7Wc65mPxOWy77hfH6tyoC223nTJlX83kwWFhbw+uuvn4nq9d709+vjFKYqi4FSKeYV\n7pqrErZ582YAwLFjxwAAe/bsAdCtJEnFmoo3lbKnn34aQOfF1vcMrxvrYbYUqtBVX9XrQ2We7aUS\nfu+99545hjnEmceb53DppZcC6HKEU+nm92RSz7R+39rfncpYebIrJcr9rs+3KmVDz7+6h6dPn545\n9Tvj+/j2ansyvmd8X874HuU7hBBCCCGEKTFY+QZqlcFFznqcKmTVLGmNOlq9nqpuVDOC9ftqFjep\nIl3nm3T+wEoN0uO13f0yqlm+vMYub2ilQrZmOdBt55Gs+k617fJ0uk+et8sP6spz5+M8aLOkgC8s\nLJzxEHO7/1mpLvqctCpBK6WIu/1c1oETJ04A6FRhKt5cFZLea/WEU21mvm3uR282y6Hire2t1N7n\nnnsOQKe0sxz2KarcALB161YA3aqc9IMzQ8uOHTsAdFlOnnjiiZGyKpxyNRTXhypfrLtmlaqpx7vy\n3H6t+1fv6lkg43vGd60r4/vo+azE+B7lO4QQQgghhCkxWPmen59flPdSoyz+619XkmpVHap8oK0R\nIstxUaBG3i4SJtVs6spnpe13Ko+beevqWyqKdTPLtY0uaq/Uzup7d01dTtNKEdNP7XNOrXHeTo2I\n+7OWx9Wv+7t6lmrfLKli8/Pzi66Zm/leKdatz5MrX6mU7laVhV5uZv6gp/qKK64A0CncVLypPFPx\n5vXhapJUvlk+Vebvf//7AIBbbrkFQOfhrqCCTgWe7aXKTWUd6N5lXP3yyiuvBNBlOWEbuVrmkSNH\nRs7ZqX+qeFeKckWlYLcqy06ZIk6JqpQ1/XT1Lvc6rDUyvi8m43vGd61nJcb3KN8hhBBCCCFMiYmy\nnbjIjpGwi+g0aqiUr0rZYn0ahVXqjMsbqrjzIOp7bJ097epzEa/ior+lytcyNTfrUEVLI1f127k+\n4tqjqoBmihiqQDmfoptdXUXY6hXTDCDEeU/725Wiu1ZYWPhF5gPNyer6t1Oax5Xbx62+RlwuZZdP\nvFWBI1SOqVAzI8gll1wCYHEeYCrgb33rW0e2qUxTqdZ2UulmPa3KN/OQU81mH6Qiv2nTpjP7apnM\niMK23XHHHSP7XXjhhSNtdYrW0HzerbR6rqvnvsr37fZ3nlT36RSxpd7ps/K8Axnf+2R8z/i+muN7\nlO8QQgghhBCmxOAVLt94441FkaX6ZdavXz/2d+cfJEPVFafSaPkuiiPOg+aUPI26qpnCzhur18Xl\npKzKb1Ecqza7CM+VqZGm89Vq/e57117nKdN6q4jXecEqD5r2Ga1X+z73p/q50krhNFlY+EW2E1VR\n+j9Mze8AACAASURBVL+3lgPUM+tbPZGT5h9W5Yzb9Duz3F27do0tn+oxlXLNJUsvNhVqbhN6wfW4\nSuVlOcxMwvafPHkSQKeMjzuWGVJ4jtdffz2ALoPKoUOHACx+Z5Pq3Vf9VaF1P/ccuvdKpVhXv2u2\nA/e8D/WEj1PUZ+WZz/iOkfPQdrcen/Hdt8vt/8s4vkf5DiGEEEIIYUoM9nyvW7fOzjomGukpjA7o\nq+Hx6q3UKIW/Vx4tF8lqFOWiL1eOi4q0HlXYtH3u+gz1PyrjrotGdq0zut09dis6uTa6HKpOSao8\nYM7bWXm8SKVwVduVaqn1j4uYXf9da1AJo7fY+fCcAlWplw7nT5w0+4m2T7MfnH/++QCACy64AACw\nc+dOAJ1SzXupeb3pm+Y21WQqg/SE8zyYR5wrYla+RsJymH+ceb2vu+66RfvSf853KzO28Biuhvnf\n//3fADoVn3W4dx9pfZ6JPjfcZvuYhYVKEtvvPJq8d2wv/8qgqxzqefDTKd7uU//q495Lk/5FYK2R\n8T3j+7jfM76PshLje5TvEEIIIYQQpsRg5fv06dOLIliiSphuV94uzcHoZju3zlJuxbXbnafSqsi1\nzhiuskhUaksf51msPFvOI+nugYt8tXztC9W5VCvoVbOgtRyN7F2kTzQypkJApc6Vo31a658FFhYW\nMD8/v+i5rJRp5+1uVbx5jSsVVhU55zHV7/U4qqd79uwB0K0KqXmMqbbSg81MIsz7zevx1FNPAVis\nnLPcvkd7KfTZYN9hOayfubsB4JlnngEAXH755QCAO++8EwBw8OBBAJ0qv3///pFz4z127x7ddsoW\ny+FfCeiT1xzlqtDr8a58bYc+d7znPE/Xl1weYrfaomac0ePce3XWyPi+mIzvGd9XY3yP8h1CCCGE\nEMKUGKx8j4sCnTpSeUKdR9RFpM7TqWi9Q/NxuujQKX4a7VWzn6v6XZRW+Z+WKteplK3RuousK29j\nldtUvVfLRSNhl89Xv9eVrZzy5o7T89E+M0uKd5/Tp08vUkWc51FVRVUdifvd+XWJ825q/ZW3U7ep\nwjJftqqm3KZXm/eYijPVD3qy2U4eT085s6j083KPQ58RXn96yuk1pzrD9gHApZdeCqBTaOljP++8\n80a+p9eayrj2e+erVWWbSjZ976ps67mosu3eH+4euvcH4e/qHW9d4c95SXleO3bsANBdR3fcrHq+\nM75nfB/Xlozvo+ezEuN7lO8QQgghhBCmxOA83/Pz84tWfiI6o5yKjEYXzhfkcjrq8UO9Wi6Sdb4m\nd36Ki/pcBO2iTbe/nkcVVY4rx3nCHJXHSSPCKhezqhNUAysfHVElS9VS10eq2dTqP6wiaF35ynm9\n9Hju17+es6KGLSws4PXXXz+jkhJee/VE66euiFcp05VnXH2H2p5Wpdtta1YGPT8q1rx/zCBC9u7d\nO9JOqsNUo1UZr5Q5lkPvOP3cqio/9thjZ46l15vHUvFm/6OCSxX9gQceAABs37595Jzo0eY2z0X7\nf+URrc5Rqd6FZKh6WL1Dq/KYU53XniuD0n+v98zlJV7LZHwfJeN7xvfVHN+jfIcQQgghhDAlJsp2\nokqR83oxGtD8nS7CdRGpRqz6vVPCKu8Zcd5SLV9nxGq0pf4fzarQOqPYRU7aTlWfxuEiRo1kGXm6\n6J3+UuJWlCKqetIjyYwRbPvjjz8+Us5NN90EoFML6W9lOZppgiv0afuqiF7PT++dmyXtVBSiEXd1\n3WcB9Q2qIlwp4KRStiuGqimt+1PBYx9y58NymRtbM2Cwbz///PMj5VGxpvLt2us++ZcH+qqphPPZ\n6Hu+uc+DDz4IADh69CgA4F3veheAbsVLZmThc09l97vf/S6A7t2l/ZV1aX5tPRe37c65ege6d7y+\nQ/W95FRYV67up+9Y+vx5b+nnZ5/QcmbpL11Axvf+eWd8z/i+muN7lO8QQgghhBCmxGDP9+nTp63q\nUClNbgUpjZQ1StFtF+lqJKoRqOYVdRG08zlpRKz1aLSoEb5uO0+ZK995wnR7XPTl8mBqZOtWgFOf\nqYvmee2eeOIJAF1ky3IZ+d56660j+6uaQCVu8+bNAIC7774bAPA///M/AIBHH310pLx3vvOdADrl\n76GHHhrbXncN1btV+e+03S4yX6lZ3m8G69atw8aNG8/cA6VSI91+Tvl2yrh7vocq54oqfNdffz2A\nTsWk+qIqCI+jkk31k9/TJ81tVZ1c5gGncFFNYrYV9jWqQlSz+/9PhVozsrBuesGvvfZaAMAjjzwy\nsp96OLWtbEP11w3F+Vv1XjgPq1Mx3fwB9WhWSniVL5jwutIbf9FFFwGAfVZmgYzvGd8zvk9vfI/y\nHUIIIYQQwpQY7PkG/OxiRjUa0bpPLUc9ZOo5c34cpyhpRKzqhUb4VWSt3i/n0XTqjpZLnA+LsDz1\nGzlva/882WZGbhqpVQqPRoqMkDUjBNtA5e0v/uIvAHS+WGZXoH+Vah6Po4rH7V/91V8F0EXIzCTB\n8qnYESp5LPeee+4ZaZ+qFhrp62xoVQycCsF7QqqVrmbJ/7l582b82q/92hlld9K2O3WSVIpalS3F\nlVP9TvhssA+dc845ADp1k31F3wPs28ylfezYsZF6qT63+qDd78xIQlVo69atI/sxE0n///ku01n7\n9FRSceI50afOc6/eMfou1nvjcrw7hVvPvcrLrVSrHrY+z5UfV5V09p0nn3xy5Hi9jrNExveM7xnf\nV398j/IdQgghhBDClBisfNMXBiz2xThvpEauLnLW3/t19n/X73Vmvipjbuaq7lfNlHVUEfGkkbD+\nrlGqi9b6/iQXqVURHCM+RrLMA8y66XHkJz1ePI5tOHDgwEjb6NXavXv3yP433njjSP28p1ToeA/2\n798/Ut4ll1wCoPOgMRczy2PETcWvWgnL+QGd30/zf7oVsvrHzYr6/Za3vAUXX3zxoueI56YeTodT\nqt1+Q5XuVu+4U745U5/qLxVs9j0+A+yT9ITv27cPQKdyUrXZsGEDgE6loS+StHo/q6wJqtT128hz\nuvjiiwF094rbzHZy5MiRkW0+T84jTdxfGTSjhXuHOqXZ+Wv1d9cO7St6jVT9bEUz+2h7+Ds94Mz/\nvdx5CdMm4/tiMr5nfF+N8T3KdwghhBBCCFNiIuXbzWAlzqPVL6P/u5upTqpI20XkxCl06vVyCpvz\nJ7o8p4pG6NUM/mqWs0bG6vPqR8YayWlbGDFSnWPEyv3pe73mmmsAADfccMPIcbwGjHgffvhhAMB1\n110HoPOgMoKmashIm6oh62MkzoiZKiKv8ZVXXjn2GuzcuXPk3KlAsbx77713pD1OndBrqiteaSRM\nqnyfGpHPCkspd61ebeKyDgzNhqLbqs7q8+veC4R9hl5q5tHmcYcPHwbQrWrIZ4SqDVVmri7JPk3l\nm555MvQvH/SO89lh+eMUPbadzw3bRpjBhZ7JO++8c2Q/p8oT5wd2/VrfrcT1DWXSvxKxfF47zfbi\nVuZzvmDXd/WvIVS8WW8/b/YskPG9I+N7xneyGuN7lO8QQgghhBCmxETZThSnDrgZpi4PJ3H5OF3k\nrKqFizSdAlF5v5y3TM+vioy1PUrlg3T5Qpeaqc+cw8ybyVnDN998M4Au4mQOYc465veaPeGuu+4C\nADz22GMAgPe85z0AutnFVAMZITN3Mn/XWdmqsjBCp2qoHkuiEWx/lT8A2LFjB4Du2mt+UPUxulnQ\n+r3OGuenzlRX+sfPiud7bm4OZ5999qLMFe65dc9Rq/e6VSFsVcxbPeK8d/Qvvve97wXQqTZcHZLK\nOFeNpA+RaidVH+2TTk2u+go/WQ79kHwmqE71s53QE8my6WNnv7/99tsBdO8Dlu1yLOs7z6l8+k5s\nVYAq5dz9FcOtouryhLvv3ZjE/Xl99BlQNVhVWZb3+uuvz5TyPY6M7xnfM76v/Pge5TuEEEIIIYQp\nMXiFyzfeeKM5X2/lBXOzehkNMYpykbBGzm6FKaeeuEhdz8flD3X16vH6e5XlwHnCFH5P3xNzZnLl\nPaBT8ejRojr3K7/yKwC6SJYeKuYS5j3gylI8jp5Sqm6MvDkrmUrbiRMnAHT3iioij3dqqLu3Llcr\nI2K9p/SS0YvG7+lxY6SsqkK1Uph+ulXO3PGz5vk+66yzrPKk74FqmwxVwJ1iVWU1Geot5/PzX//1\nXwA6/+Fll10GoFNt+Mn3Ez/5HD7zzDMAOnWHv9NX7fIf68x5bvOZ4TOoGTX4DAKdp5sKED3dVMYI\nc5MzPy/rZBudmqcKsPNAKk4Ncu9G5/fVrCPq91WlWn93WVC0XFXKnWdUz1vzqs8SGd9Hj8/4nvF9\nNcf3KN8hhBBCCCFMiYmUb41sGZ04z5RGM07VUDS/J7fdzF4Xbamq4Wbgu1nRLnJ1qk+lHLjyXGRO\nNeW+++4D0M0k/vjHPw6g83nqDGKg84AR5vP9j//4DwBdBPvbv/3bALqImXXTK0Z/K79nnVQB2Xaq\ncfSWuYiS90LVErcynvOY6n66Ihd/13ylX/va10bO33nDVIV099ytTuZW0JoF5ubmcNZZZzV7tlsV\nM6KKVKsSXinYzvPt3jPsM5qXm1lOuMIkFSf6DZnFRFUjfq8qD9Unfe6paKnaSh8lj6NKzdUU2T56\n0IFO8aaXk+fE9wCfT0UzqOg73SnXlWdbcVlDiPurCdvDdmrmF56nKmUuI0f1vDu/rVNBnUI2S3M8\nMr5nfM/4Pr3xPcp3CCGEEEIIU2JwtpN+3lL1PLlIsn9sf7/WCNnNmnYqhPMlaq7XSsGr/Iwa1SnO\ns6ar0KnnlH4rek7f//73A+gUCCphjE71un3xi1888/+XXnopAODd7373yL6MqjmrmXkyGSkyswL9\nZsyzyW22WfMIU5Gq1BFdBc2tHOc8oBphsx4qYK58qpY8/89//vMj+6vvViNenQ1deTt1/37Zax0q\n3/o8tSrh48obt10p1tX++rtTPd3zSiWJn+zDVH3YB+jlZkYArmhJqCJpzlunvnJbveNUuKliqy+b\nn7qqW78utl1zhPNesi7+zra77AOVyucUcKdeEs0qwnca7wX/msDv9Z2paqZT1p2q6fy9bmVA7WPu\nvTCLf+kCMr73yfie8X01x/co3yGEEEIIIUyJwZ7vcf+qVz+cm13scq8yatBcjq4ejaSr+vR3Xbmr\n8mqpN819qmrDaIwKFlePoof0xhtvBABcccUVALqZyZxh7KI/XbWN3lDy6U9/+sz/0xP5s5/9DEAX\nVdOXylX7GDHu27dvpE6NSBl5klZfm8tg4XK3Ks73pyqLRuAKr8fFF18MAPiDP/gDAMDf//3fA1ic\nxUBzvVb5P523jDhFba2ybt06m+WEtCrarV7wqlzddop8q3KlSpq+j/gsUPmmckX/IxUt+i0PHTo0\nUg/918eOHQPQ9RGqSlSdXd/le0XVI75n2AeBTtFWRcjl8+bzrG1wuZlJlclCj2c9bPO2bdsAdD56\nPUd3L4k+j04Bd1R/Zak8nXqdKoV9Fsj4nvE94/v0xvco3yGEEEIIIUyJiTzfGvVr5OhUElUJ3OpC\nlVeriogVrY/1UJFS/xAjVPomqVDxU7MPMDKlisMV8Xbv3g2gU8hYD9UpbT/bx8ia+9OHRXgc20FF\nTmck99vEGdSc7czoujUiVSp10800dzPFVV1xkbQ7Trf1e+fDY7m/8zu/AwD4whe+AGBxxKt9Vb1g\n6v1SRa7vZZsVzzfwi+s0qQqxVJnjPvX3att9OsXbqSqaSYM5sZkDl/eSuWP5LFHBoi+Z95rvFbaD\n7xN9T1FJo0rDPkclXRU8VWlI/z7w2ddz5zuKZXKb56xZUFwmGu27qsZrtgTmE6cCx3eqW3HSfWr9\nOuY4Jb5VwVdUudPnWJ8BVSuHrvS5Vsj4nvG9f1zGd4zst5Lje5TvEEIIIYQQpsSy8nxrhOoUKKdE\nUTVRnwwjR92PvkTOuGWUw9/drGeqO4wG+cmZv7piHP1SnI1MFYdRJvfTqIcRskY+jMD1uvGTihqV\nNPqzeB68PjxP1sN2cv9xM2+5IhX3JS6XqlLlRnaZMEi1eperR895KNo3VXXh77y3VAx+8zd/EwDw\n1a9+FcBiFbOa/ewidY2wZ4G5uTmcffbZE3uzh3q29XunfFVK96Se88v+dyXLu+++G0DXty+//HIA\ni+8hlTP2USrgVLKYDYXbmr2A/kp6yIlbdZHHUxlfKqsD3x1aNtvCdye914rLw+vq5LkzawJXxKPK\nqOVUnmitxynaLouC1ueeS1cv0dVdXV5jXi9eV6fEr2Uyvmd8Jxnfx7OS43uU7xBCCCGEEKbEoLBj\nbm4O69evX7SKmEZs6uvh95o9gKsz8ZORr0ZNLI/+QaopOjOXx1HdYdTG6Gfr1q0AFuff1dy3Go1p\n5M3yNeLn8Vwtiudz5MgRAMCuXbsAdJE6PzVfr84Q1lWs1G/Uz3bQb2e/LOI8kK1ZDtwKVVq+U0P0\nd/VaqdKk5+SUN7fKmipnbsY81Y5rr70WQLeK4He+8x0AnXpS5YStIuNZY25ubpGS06owVzPhW7Om\nOFqzmbi+or/Ti/ne974XAPDtb38bQHfv6AF/9tlnAXTvH75X2JfZV1Txcyv6uRnyfF9yP75H+T4b\n16f4LqCiQ98q1Te++/gu4jlUGR+0f/PdRoWb+Yb5Tquyjjg11eV8Ji4/N1F/7Uqh3m+XOYPwfNav\nX1/247VCxveM7xnfpze+R/kOIYQQQghhSgxSvtevX4+dO3eeiUjpydJ8s6rYqCeKv3OGLr1WjFx1\n5v2ZxkpuSqVaGY9o5MzzYQStShTby/NgZM3zZV5Pzn5mJKs5bfW6EP6ukT6P15yzxOVD7Uf2ToFS\npanKEqBUs5u1bW52tMsDWs16rnyHur9TW3kPec3o433f+94HoFM1Dhw4MHJebvZzlbXhjTfemLls\nJ8TdS+fdnqQOoFa0W6lUHt2P94gK1kc/+lEAwJ133gmgU7zYR6hssS/zfcjv+TzT+63KoX461Uef\nTXpH1c/dr4OKNzMlUKWjr53vFlWItR/z+eDx9MnyGvFdSFqfR91f30Pu+SV6zVyGjEqxcu0hVX5v\np+DNIhnfM76TjO+rP75H+Q4hhBBCCGFKDFK+zz77bGzZsmVRZMxIVvNQ6mpnOhuZx6v3UWfks1yq\nOqyf5fOT399///0AutnOe/bsAdBlMWBke9111wHoVqY7fvw4AOCiiy4C0EXKjz32GIDOk0b/JOvj\n/oxk1ZPJ+l1EpBExcb4nlsPrs1T+VI2qXd5epxhpOW6baETsImOl1ZvmPF2MtLXPVSqtq4/3+hOf\n+ASATr08fPjwyPEu36cqDbO44t3c3NyI53tSFXGogl15xavsKq1qa/U982/T60kFnO8J9VHz+Sf0\nrlIJZ2YCvt+oyrh86exbPI7vIR4/TtWid5G+dKqOqlSrwkzVj7D/893FjAsuj7h7j7T2e6fMtc4D\nqLzerpyhfbQ1007l51+LZHzP+O62Scb3lRvfo3yHEEIIIYQwJSZKsqjRFBUcRniqPmgk61QR7nfs\n2DEAXXSiq7GxPpbDaIUz7jkDn5+Mhm666SYAXTTECJmRPD1q6t1i7lq2T7MVsJxq5ruLPnW2te5f\nzcDV8sapLS5Sdd4sfupM68pTWWWwcOegah5VBm2XRt6aL1T7XuUJpbqg7WGf4L3nCln/8A//AKDz\niunM+cortrAwWytcAnX2ktbjFH2OhmY3cepO5Q90q6zxudf66JPmvaY/kN5rPiPsw3wfsB5+r9va\npzXbAhV3KnF8D/J3qtX9vMl8R+7btw/AYl8p28xj6eVmLnN6uvkudPmtte2k8nK6e0halaPqrx+u\nT7jjieuL+l5xeYaVWXvWgYzvGd8zvk9jfI/yHUIIIYQQwpQYpHy/9NJLOHDgAD7ykY8A6Gb/01/I\nWcCcUcqogJ4pzs6nF5KfjGbou+H+ujoaUT8P8+9qRKteSv3ezZB10Z2LpjTS120er1GUm1GseUk1\nqwEj9MrH1f+uyp+p0TfvnfPduqhdr6nziKkqwu+PHj0KoFM11DfY6tV0ypgqAURVT0I1hn3yD//w\nDwEAf/M3fwOgyybB66XXRb+nj3oWYBRfXesq0neqSXW89o3WXLVD20f4vKm/kJ/0TTN7wT333AMA\nePDBBwEAhw4dAtC9x6gqqWKlWR34u2ZDYd/ncWwfV5Okckj1GlisHrJMKt3M2MBPerl5HKm8o1Ue\n7cp3T1rvjctuoO9Q9xy7/NzV+8P58fX4Kgf+LJDxPeN7xvfpje9RvkMIIYQQQpgSg5Tvc889Fx/7\n2MfOqCmMFqiiaF5NzQHLiJlRCCME7k/fof7uojmNNDV6chEvj3M5W93xWo5Gaert0gieqPqiyhaj\nMapVnN3NKJHXi9eJ6tU4f6OqeA71WFVZBjSK12tFjxdhm5l/WHO9sjxmZ2DWBr2G1ezqata0bjtV\nlvWxnWwX9/u93/s9AMC//Mu/AOhUnUrJmyUlDBj1sFXnpl7JcWUB7RksWjNqqF+wKr/KdsJy+Ozo\nynjsE+95z3sAANdccw2ATiVhX+A2lUN6t9m3NcOI+i81u4JmTdD3J9C9Y/kdVXGqjPrO03eY82C2\nZrppVbx1f6V6Xl37KyVPFXvXfjfm6H6qbur+Z5999sw88xnfR8vJ+J7xfTXH9yjfIYQQQgghTIlB\nyvfCwgJeeeWVMxEa/5XPCE09kowQ1ePocqI6X5JGRc5P5Hx6LkJ1VJFxNVuZ24wC9TjNtUvFiwqZ\nlst8pdxmxOyuW3+78h66WcakdfYzI0PNi8lon37Bu+66C0Cnpqg/kH3LZZ5o9R+3qqC67Wam83w0\nm8QnP/lJAMC//du/AejUTacYzs/Pz2QGhJWgNRtJ5Zsd+r1S9R2957qt+bn5yT5+4YUXjhynM+N5\nPJ9jbqtHXNurz9xSKwK6d6SW6TzL4/ptS9uI6+P6vnHtrbKVOKp6q7+mtJbn3oeqQM6S8p3xffT3\njO8Z31dzfI/yHUIIIYQQwpQYnOf77LPPXhQBM0LTmas6A5b+Gl3ZSiM7zfOpka3zJdKrxv3pQ2K0\npu1TL5ij8hfp72wPo0LNoqDnxXYxiwJR5cxFr7o9bmZvtbKV/q4Ro0aKeg5sI6N2PRf6VumT1TZq\nn6nujcvVrGjfaVVN9VprxM1Inrll6dv7+te/DmDxjHkya6p3/zotV4FuVabdDH6n0rr2LZdKBXbv\nKXeeuh8VMlVfVFWpvu/3Kac6umvj3l1kaLaSSilX9L2iz1+VA9l9Vu8796ntrhRD51duHVvWGhnf\nM76PO4eM7ys/vkf5DiGEEEIIYUoMUr7n5uZw1llnLVrJqv870EUtXCWI29dffz2ALq8lZ+K71cPU\nS6aRuOLyflZRkJsxXylsGp3xeEZFzMOrKo7zvlWKn0axLjfmOLWI+6qKRlo9mwr3o89VZ3hr5Ox8\nqpphwnlDFfUdarvcLOdKCdTInPeU31OF4T3+jd/4DQCdD5A5oKkAPPDAAwAWZ7iYBfQ5qLIEVP1Y\n9x9K1Y6K1gwXrl4yNJOGq0/7eqvPeanzd+8sp/RWx7lyqvqXeieNK8fdm8oLXp1XpaRX70VdVdCp\nk5rx56yzzpoZz3fG9/HnmfE94/tqjO9RvkMIIYQQQpgSg7Od9BWAkydPAgAOHz4MADj//PMBAO9+\n97sBAFu3bgXQRQfM7Xjs2DEAna/G+Yw0EnaeSp2NXe2nkXbl71PUT+miSqfQaT1sh0aTGsXq7Gfn\nm+orDdoWPdbN/tdz1e1Wtc/NiHdU5bq+ojgfripkTmVxETJ9hvS80b/IHLaf/exnAQBf+9rXAACn\nTp0CAHzoQx86U96XvvSlsXWuNebm5rBu3brmHKyOagZ7v76W452/t2K5CmSVUcA9S5X/2Snd+ry7\n67+UiuXKrtrU+g5090b3c/7fVk+5a68q0u74qg9pO/n+0U89j+ovBZP+debNIOM7Ro7P+J7xfTXH\n99l5M4QQQgghhDDjDFK+X3rpJdx2221nVr7as2cPgG51IPpmGAVxxStGR//5n/8JAPjoRz8KoIsE\nGbG6aIboak4s10W8LkuCyyNaRcrOo+miPfU56feuvfTMMS/ooUOHAHQr3u3evRtAd92raHbcubht\nzb3qcJ4uvZbEeSSdYqar/alaQJwPztXnImPnPVMPGc+LETLbwz7IPKH8/MY3vjFy/LZt2xatVLiW\nGedZdWrqUCW6UqJalWKn8rQq1ZXHutUTXqm+rf5pp562tNtdG/3dZUeoruGQ2fzjjq9ozb5SeVid\nAujeW05hd/5dstzrs5bI+J7x3dWR8X3lx/co3yGEEEIIIUyJwZ7v+fl5vPOd7wTQRQe6ahEjOnrG\nmP/zwx/+MIAuwuP+/NQ8n/zU352ipJG1y+Gon4x2NMJ2ka9GvMzzqbktOfP1mWeeAdBFnfQJPfro\nowCAc889FwBw4sQJAJ1Xbv/+/QA6j51GczorexxOIXJRu5bpVMUqL2hFld9X/Xbqj9P26Gxv4rym\nvFeqZFVeMa2XfYeRMJ8FPhus//Of/zwA4Kmnnpq5jCeVAlR5It1+Qz3gTrV1fdG1p1J3qywJul/l\ne26tp1UlVpWof1ylvGobnYe5ugaVh1rbsdQ7alz79H1SKdKkaofuR5zCXp2f86K7985aJuM7Rr7P\n+J7xfTXH9yjfIYQQQgghTIlByvdrr72Go0eP4vjx4wC6FdoYddCj9K1vfQsA8IlPfAJANytaPWMa\nATOK0NnNGj3prGc9XqOqynPpvtfoSKO0l19+GQBw4MABAJ0HjlESI9zzzjtvpDxGypdccslIORdf\nfDGAX0RPAHDw4EEAnZJAnxTL27Vr10i7SD8KbFUlifNcuejbRbBu5jbRa6yRq0bm2hec91KVKvW4\n6fHuOmi7mPeTnxr5Uh3hvaQ6xHZzlvQ///M/lxkaZhWnVA/1/SpOydZ6nUrZ2q5Wj7hS+QpbqGdq\n0wAABe9JREFU62llqb9EVIpr6zvQMdTT7BT2av/W9ldKdJXVhbj2qYI4blXRcfv12zcrPvCM7xnf\nlYzvqze+R/kOIYQQQghhSgxSvrds2YJf//Vfx9133w2gi8yY35OR22c+8xkAiyNhjYjdLGa3spZG\nUy5yveuuu0bax8jc+Xm0HI3m3CpKmzZtAgD8v//3/0aOI4zueF0YPT399NMjx9MLRu8coyu2j9EY\nV5mip0zPexwuanZeT+efczPLNWJ2OU0rf51rp0beGoFrpKsz5V15mreX2y+88MLI9+yjVIO4whXL\noZ+PPi/eY7aDzwD3+63f+q0zSspaZ25u7sx/Leg1Xqrc5fxeHTep0rhUFpFxv6uPsZXWfMOOFhXZ\nZYBQluvPb73Wrdeo1bPtyq/umVttsGpPa1aUcSsMzorynfEdI/tnfM/4vprje5TvEEIIIYQQpsQg\n5XvdunXYtGkTPvjBDwLoIjn+65+fbgUrF2kS59HS8nTWsc7gZWRJVOVQj5iLllx0SJ588kkAwAUX\nXDBSL6Oo559/fmR/erm2b98+sv++ffsAdF4wjepYDuvh+TNidtFj/5yUcQpNf9t5KSt/q0bELtOE\nU+Tc7OzKj+vyexKqE4xg1Zd19OhRAItz19L7xePV18c+z3Zo39R2nX/++YtypK5V6Fcd6guusoSQ\nKr93a6YNd5y2x9XTivNXVvU4XO7cSp11mTmW+s75Yt3z7lC1v8rs0pptxCnelX9f39GuHteHWvOI\nu/paVwCcBTK+Z3zP+D698T3KdwghhBBCCFNikAQ3NzeH9evXL4o6nKrSP27cfi7q0Rm1/J1RiJar\n7bj55psBeHVDozZVmvTzzjvvBNBFSWwXvXD0+xBGR5wtzv3oF+InozFGSvye3i+28+qrrwYA3Hff\nfQC6CFv9R2SpyNjlzdUI1nmu1Hvlcq5qhOwyVrjvXWTu+g6vBdUKRrjHjh0DAOzduxdAp0bwnvA8\nGPly5rmiK17t3LlzpH06e7v6nBXGtbfyB1fnqPd0Uu/zcrOGODW1yq6yXKr6tN4hXnaXFaA1k8vQ\nfNxD+/dQZbkqr1Luq6wplXKtY5fiPLSuvLVMxveM7xnfpze+R/kOIYQQQghhSgw2n87NzZXRjtLq\nI3QRMr1nGilz5iqjMM4y3bNnD4AuwtR2qIdKo0SdvczymduRn2zfjh07AHQeLUbEbCejMM5+ZpTF\nlcSIrsqk29u2bQOwOBLWyH4cbjYx0chWI2j9nTgPpVOg9B60qiU8XvN6/uAHPwDQ5VzlbOXLL798\nZJvXjJGv5hXlzHntY+56uRW3iF5vnufGjRsnVnrfLJzCpNdQ9289z8qT7fqIHt/qwa7UYKXyQWq5\nimufU31ajxui/Fd+eKc8OUWn8mpW14K0KtzV+6V1P3c+rR50xb0nZ8nr3Sfje8b3PhnfV298n61/\nBYQQQgghhDDDTOT51si4Uj+c/4heqzvuuANA5+VilMMI8x//8R8BAB/72McAdJEyfT/f+973AHTe\nKXq0nHpBbxVnxm7ZsgUA8MgjjwAAbrnlFgBd9HPZZZcB6KIgRsyMhBmtMfLVmbOcxUxPm86YZXmc\nDc3Z1FxRjHlMedzhw4cBANdcc83Ieal/q4+LcF0krBGi5st0yk6VPcDNQFfUd+jacd11141tF9UH\n3lt6wTTydu1Vj5fmdKUqo+rFyZMnAQCXXnrp2PKrHNhrkcqnV/lhydBsKUN/rxSHoR7x6v3m6pt0\npUu3MtoQBV+vuXveXR2V8tXaNtced7zzelcebvdXl6rPOlz9Q8vtv9dmxfed8T3je8b36Y3vUb5D\nCCGEEEKYEnNDovK5ubmnATyyes0J4ZeCSxcWFs57sxtRkec9hBUhz3sIvzw0Pe+D/vEdQgghhBBC\nmJzYTkIIIYQQQpgS+cd3CCGEEEIIUyL/+A4hhBBCCGFK5B/fIYQQQgghTIn84zuEEEIIIYQpkX98\nhxBCCCGEMCXyj+8QQgghhBCmRP7xHUIIIYQQwpTIP75DCCGEEEKYEv8fp342vqPGD8QAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f42bc504a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000493722 Not Bottle\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('seaborn-poster')\n",
    "pairs, cat = loader.jam_detector()\n",
    "\n",
    "# inputs = pairs\n",
    "p=np.array(siamese_net.predict(pairs))\n",
    "\n",
    "l = np.where(p==np.max(p))\n",
    "if p[0][0]>0.1:\n",
    "    result = pairs[1][0,:,:,:].reshape(105, 105)\n",
    "    out = 'Bottle'\n",
    "else:\n",
    "    result = pairs[0][0,:,:,:].reshape(105, 105)\n",
    "    out = 'Not Bottle'\n",
    "    \n",
    "\n",
    "plot_oneshot_result(pairs, result)\n",
    "print(p[0][0], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 10000 epochs : 84.3%\n"
     ]
    }
   ],
   "source": [
    "def test_accuracy(epochs=100):\n",
    "    acc = 0\n",
    "    for _ in range(epochs):\n",
    "        pairs, cat = loader.jam_detector()\n",
    "        p = siamese_net.predict(pairs)\n",
    "        \n",
    "        if (p[0][0]>0.1 and cat == 0) or (p[0][0]<=0.1 and cat == 1):\n",
    "            acc += 1\n",
    "    \n",
    "    return f\"{acc/epochs*100}%\"\n",
    "\n",
    "epochs = 10000\n",
    "print(f\"Accuracy for {epochs} epochs : {test_accuracy(epochs)}\")   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T14:53:55.802869Z",
     "start_time": "2017-11-27T14:53:55.771669Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0277789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1, 105, 105, 1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p[0][0])\n",
    "np.array(pairs).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling data for feeding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T11:16:26.352319Z",
     "start_time": "2017-11-27T11:16:26.280117Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assemble_සිංහල_dataset():\n",
    "    import os\n",
    "    fpath = \"./Sinhala\"\n",
    "    f = open(\"./සිංහල.pickle\", \"wb\")\n",
    "    Xs = []\n",
    "    for i in range(1, 5):\n",
    "        l = os.listdir(f\"{fpath}/{i}\")\n",
    "        අකුර = []\n",
    "        for j in l[:20]:\n",
    "            im = image.img_to_array(image.load_img(f\"{fpath}/{i}/{j}\", target_size=(105, 105)))\n",
    "            im = im[:,:,0]\n",
    "#             print(i, j, im.shape)\n",
    "            අකුර.append(im)\n",
    "        Xs.append(අකුර)\n",
    "    pickle.dump(np.array(Xs), f)\n",
    "\n",
    "def assemble_dataset(fpath, num_classes, num_examples, pickle_file):\n",
    "    import os\n",
    "    f = open(pickle_file, \"wb\")\n",
    "    Xd = []\n",
    "    m = os.listdir(f\"{fpath}\")\n",
    "    for i in m:\n",
    "        l = os.listdir(f\"{fpath}/{i}\")\n",
    "        x = []\n",
    "        if len(l)>= num_examples:\n",
    "            for j in l[:num_examples]:\n",
    "                im = image.img_to_array(image.load_img(f\"{fpath}/{i}/{j}\", target_size=(105, 105)))\n",
    "                im = (im[:,:,0]+im[:,:,1]+im[:,:,2])/3\n",
    "                print(i, j, im.shape)\n",
    "                x.append(im)\n",
    "            Xd.append(x)\n",
    "    pickle.dump(np.array(Xd), f)\n",
    "    print(np.array(Xd).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T14:46:07.830369Z",
     "start_time": "2017-11-27T14:45:58.877457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives 1000.bmp (105, 105)\n",
      "positives 1001.bmp (105, 105)\n",
      "positives 1002.bmp (105, 105)\n",
      "positives 1003.bmp (105, 105)\n",
      "positives 1004.bmp (105, 105)\n",
      "positives 1005.bmp (105, 105)\n",
      "positives 1006.bmp (105, 105)\n",
      "positives 1007.bmp (105, 105)\n",
      "positives 1008.bmp (105, 105)\n",
      "positives 1009.bmp (105, 105)\n",
      "positives 1010.bmp (105, 105)\n",
      "positives 1011.bmp (105, 105)\n",
      "positives 1012.bmp (105, 105)\n",
      "positives 1013.bmp (105, 105)\n",
      "positives 1014.bmp (105, 105)\n",
      "positives 1015.bmp (105, 105)\n",
      "positives 1016.bmp (105, 105)\n",
      "positives 1017.bmp (105, 105)\n",
      "positives 1018.bmp (105, 105)\n",
      "positives 1019.bmp (105, 105)\n",
      "positives 1020.bmp (105, 105)\n",
      "positives 1021.bmp (105, 105)\n",
      "positives 1022.bmp (105, 105)\n",
      "positives 1023.bmp (105, 105)\n",
      "positives 1024.bmp (105, 105)\n",
      "positives 1025.bmp (105, 105)\n",
      "positives 1026.bmp (105, 105)\n",
      "positives 1027.bmp (105, 105)\n",
      "positives 1028.bmp (105, 105)\n",
      "positives 1029.bmp (105, 105)\n",
      "positives 1030.bmp (105, 105)\n",
      "positives 1031.bmp (105, 105)\n",
      "positives 1032.bmp (105, 105)\n",
      "positives 1033.bmp (105, 105)\n",
      "positives 1034.bmp (105, 105)\n",
      "positives 1035.bmp (105, 105)\n",
      "positives 1036.bmp (105, 105)\n",
      "positives 1037.bmp (105, 105)\n",
      "positives 1038.bmp (105, 105)\n",
      "positives 1039.bmp (105, 105)\n",
      "positives 1040.bmp (105, 105)\n",
      "positives 1041.bmp (105, 105)\n",
      "positives 1042.bmp (105, 105)\n",
      "positives 1043.bmp (105, 105)\n",
      "positives 1044.bmp (105, 105)\n",
      "positives 1045.bmp (105, 105)\n",
      "positives 1046.bmp (105, 105)\n",
      "positives 1047.bmp (105, 105)\n",
      "positives 1048.bmp (105, 105)\n",
      "positives 1049.bmp (105, 105)\n",
      "positives 1050.bmp (105, 105)\n",
      "positives 1051.bmp (105, 105)\n",
      "positives 1052.bmp (105, 105)\n",
      "positives 1053.bmp (105, 105)\n",
      "positives 1054.bmp (105, 105)\n",
      "positives 1055.bmp (105, 105)\n",
      "positives 1056.bmp (105, 105)\n",
      "positives 1057.bmp (105, 105)\n",
      "positives 1058.bmp (105, 105)\n",
      "positives 1059.bmp (105, 105)\n",
      "positives 1060.bmp (105, 105)\n",
      "positives 1061.bmp (105, 105)\n",
      "positives 1062.bmp (105, 105)\n",
      "positives 1063.bmp (105, 105)\n",
      "positives 1064.bmp (105, 105)\n",
      "positives 1065.bmp (105, 105)\n",
      "positives 1066.bmp (105, 105)\n",
      "positives 1067.bmp (105, 105)\n",
      "positives 1068.bmp (105, 105)\n",
      "positives 1069.bmp (105, 105)\n",
      "positives 1070.bmp (105, 105)\n",
      "positives 1071.bmp (105, 105)\n",
      "positives 1072.bmp (105, 105)\n",
      "positives 1073.bmp (105, 105)\n",
      "positives 1074.bmp (105, 105)\n",
      "positives 1075.bmp (105, 105)\n",
      "positives 1076.bmp (105, 105)\n",
      "positives 1077.bmp (105, 105)\n",
      "positives 1078.bmp (105, 105)\n",
      "positives 1079.bmp (105, 105)\n",
      "positives 1080.bmp (105, 105)\n",
      "positives 1081.bmp (105, 105)\n",
      "positives 1082.bmp (105, 105)\n",
      "positives 1083.bmp (105, 105)\n",
      "positives 1084.bmp (105, 105)\n",
      "positives 1085.bmp (105, 105)\n",
      "positives 1086.bmp (105, 105)\n",
      "positives 1087.bmp (105, 105)\n",
      "positives 1088.bmp (105, 105)\n",
      "positives 1089.bmp (105, 105)\n",
      "positives 1090.bmp (105, 105)\n",
      "positives 1091.bmp (105, 105)\n",
      "positives 1092.bmp (105, 105)\n",
      "positives 1093.bmp (105, 105)\n",
      "positives 1094.bmp (105, 105)\n",
      "positives 1095.bmp (105, 105)\n",
      "positives 1096.bmp (105, 105)\n",
      "positives 1097.bmp (105, 105)\n",
      "positives 1098.bmp (105, 105)\n",
      "positives 1099.bmp (105, 105)\n",
      "positives 1100.bmp (105, 105)\n",
      "positives 1101.bmp (105, 105)\n",
      "positives 1102.bmp (105, 105)\n",
      "positives 1103.bmp (105, 105)\n",
      "positives 1104.bmp (105, 105)\n",
      "positives 1105.bmp (105, 105)\n",
      "positives 1106.bmp (105, 105)\n",
      "positives 1107.bmp (105, 105)\n",
      "positives 1108.bmp (105, 105)\n",
      "positives 1109.bmp (105, 105)\n",
      "positives 1110.bmp (105, 105)\n",
      "positives 1111.bmp (105, 105)\n",
      "positives 1112.bmp (105, 105)\n",
      "positives 1113.bmp (105, 105)\n",
      "positives 1114.bmp (105, 105)\n",
      "positives 1115.bmp (105, 105)\n",
      "positives 1116.bmp (105, 105)\n",
      "positives 1117.bmp (105, 105)\n",
      "positives 1118.bmp (105, 105)\n",
      "positives 1119.bmp (105, 105)\n",
      "positives 1120.bmp (105, 105)\n",
      "positives 1121.bmp (105, 105)\n",
      "positives 1122.bmp (105, 105)\n",
      "positives 1123.bmp (105, 105)\n",
      "positives 1124.bmp (105, 105)\n",
      "positives 1125.bmp (105, 105)\n",
      "positives 1126.bmp (105, 105)\n",
      "positives 1127.bmp (105, 105)\n",
      "positives 1128.bmp (105, 105)\n",
      "positives 1129.bmp (105, 105)\n",
      "rawdata 100.bmp (105, 105)\n",
      "rawdata 101.bmp (105, 105)\n",
      "rawdata 102.bmp (105, 105)\n",
      "rawdata 103.bmp (105, 105)\n",
      "rawdata 104.bmp (105, 105)\n",
      "rawdata 105.bmp (105, 105)\n",
      "rawdata 106.bmp (105, 105)\n",
      "rawdata 107.bmp (105, 105)\n",
      "rawdata 108.bmp (105, 105)\n",
      "rawdata 109.bmp (105, 105)\n",
      "rawdata 110.bmp (105, 105)\n",
      "rawdata 111.bmp (105, 105)\n",
      "rawdata 112.bmp (105, 105)\n",
      "rawdata 113.bmp (105, 105)\n",
      "rawdata 114.bmp (105, 105)\n",
      "rawdata 115.bmp (105, 105)\n",
      "rawdata 116.bmp (105, 105)\n",
      "rawdata 117.bmp (105, 105)\n",
      "rawdata 118.bmp (105, 105)\n",
      "rawdata 119.bmp (105, 105)\n",
      "rawdata 120.bmp (105, 105)\n",
      "rawdata 121.bmp (105, 105)\n",
      "rawdata 122.bmp (105, 105)\n",
      "rawdata 123.bmp (105, 105)\n",
      "rawdata 124.bmp (105, 105)\n",
      "rawdata 125.bmp (105, 105)\n",
      "rawdata 126.bmp (105, 105)\n",
      "rawdata 127.bmp (105, 105)\n",
      "rawdata 128.bmp (105, 105)\n",
      "rawdata 129.bmp (105, 105)\n",
      "rawdata 130.bmp (105, 105)\n",
      "rawdata 131.bmp (105, 105)\n",
      "rawdata 132.bmp (105, 105)\n",
      "rawdata 133.bmp (105, 105)\n",
      "rawdata 134.bmp (105, 105)\n",
      "rawdata 135.bmp (105, 105)\n",
      "rawdata 136.bmp (105, 105)\n",
      "rawdata 137.bmp (105, 105)\n",
      "rawdata 138.bmp (105, 105)\n",
      "rawdata 139.bmp (105, 105)\n",
      "rawdata 140.bmp (105, 105)\n",
      "rawdata 141.bmp (105, 105)\n",
      "rawdata 142.bmp (105, 105)\n",
      "rawdata 143.bmp (105, 105)\n",
      "rawdata 144.bmp (105, 105)\n",
      "rawdata 145.bmp (105, 105)\n",
      "rawdata 146.bmp (105, 105)\n",
      "rawdata 147.bmp (105, 105)\n",
      "rawdata 148.bmp (105, 105)\n",
      "rawdata 149.bmp (105, 105)\n",
      "rawdata 150.bmp (105, 105)\n",
      "rawdata 151.bmp (105, 105)\n",
      "rawdata 152.bmp (105, 105)\n",
      "rawdata 153.bmp (105, 105)\n",
      "rawdata 154.bmp (105, 105)\n",
      "rawdata 155.bmp (105, 105)\n",
      "rawdata 156.bmp (105, 105)\n",
      "rawdata 157.bmp (105, 105)\n",
      "rawdata 158.bmp (105, 105)\n",
      "rawdata 159.bmp (105, 105)\n",
      "rawdata 160.bmp (105, 105)\n",
      "rawdata 161.bmp (105, 105)\n",
      "rawdata 162.bmp (105, 105)\n",
      "rawdata 163.bmp (105, 105)\n",
      "rawdata 164.bmp (105, 105)\n",
      "rawdata 165.bmp (105, 105)\n",
      "rawdata 166.bmp (105, 105)\n",
      "rawdata 167.bmp (105, 105)\n",
      "rawdata 168.bmp (105, 105)\n",
      "rawdata 169.bmp (105, 105)\n",
      "rawdata 170.bmp (105, 105)\n",
      "rawdata 171.bmp (105, 105)\n",
      "rawdata 172.bmp (105, 105)\n",
      "rawdata 173.bmp (105, 105)\n",
      "rawdata 174.bmp (105, 105)\n",
      "rawdata 175.bmp (105, 105)\n",
      "rawdata 176.bmp (105, 105)\n",
      "rawdata 177.bmp (105, 105)\n",
      "rawdata 178.bmp (105, 105)\n",
      "rawdata 179.bmp (105, 105)\n",
      "rawdata 180.bmp (105, 105)\n",
      "rawdata 181.bmp (105, 105)\n",
      "rawdata 182.bmp (105, 105)\n",
      "rawdata 183.bmp (105, 105)\n",
      "rawdata 184.bmp (105, 105)\n",
      "rawdata 185.bmp (105, 105)\n",
      "rawdata 186.bmp (105, 105)\n",
      "rawdata 187.bmp (105, 105)\n",
      "rawdata 188.bmp (105, 105)\n",
      "rawdata 189.bmp (105, 105)\n",
      "rawdata 190.bmp (105, 105)\n",
      "rawdata 191.bmp (105, 105)\n",
      "rawdata 192.bmp (105, 105)\n",
      "rawdata 193.bmp (105, 105)\n",
      "rawdata 194.bmp (105, 105)\n",
      "rawdata 195.bmp (105, 105)\n",
      "rawdata 196.bmp (105, 105)\n",
      "rawdata 197.bmp (105, 105)\n",
      "rawdata 198.bmp (105, 105)\n",
      "rawdata 199.bmp (105, 105)\n",
      "rawdata 200.bmp (105, 105)\n",
      "rawdata 201.bmp (105, 105)\n",
      "rawdata 202.bmp (105, 105)\n",
      "rawdata 203.bmp (105, 105)\n",
      "rawdata 204.bmp (105, 105)\n",
      "rawdata 205.bmp (105, 105)\n",
      "rawdata 206.bmp (105, 105)\n",
      "rawdata 207.bmp (105, 105)\n",
      "rawdata 208.bmp (105, 105)\n",
      "rawdata 209.bmp (105, 105)\n",
      "rawdata 210.bmp (105, 105)\n",
      "rawdata 211.bmp (105, 105)\n",
      "rawdata 212.bmp (105, 105)\n",
      "rawdata 213.bmp (105, 105)\n",
      "rawdata 214.bmp (105, 105)\n",
      "rawdata 215.bmp (105, 105)\n",
      "rawdata 216.bmp (105, 105)\n",
      "rawdata 217.bmp (105, 105)\n",
      "rawdata 218.bmp (105, 105)\n",
      "rawdata 219.bmp (105, 105)\n",
      "rawdata 220.bmp (105, 105)\n",
      "rawdata 221.bmp (105, 105)\n",
      "rawdata 222.bmp (105, 105)\n",
      "rawdata 223.bmp (105, 105)\n",
      "rawdata 224.bmp (105, 105)\n",
      "rawdata 225.bmp (105, 105)\n",
      "rawdata 226.bmp (105, 105)\n",
      "rawdata 227.bmp (105, 105)\n",
      "rawdata 228.bmp (105, 105)\n",
      "rawdata 229.bmp (105, 105)\n",
      "(2, 130, 105, 105)\n"
     ]
    }
   ],
   "source": [
    "assemble_dataset(\"./Image_Data/Jam_Bottle\", 2, 130, \"./jam_bottles.pickle\")\n",
    "# assemble_dataset(\"./Image_Data/COCO_val\", 1000, 20, \"./_coco_data/val.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 20, 105, 105)\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./සිංහල.pickle\", \"rb\")\n",
    "Xs = pickle.load(f)\n",
    "print(Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T11:22:04.079905Z",
     "start_time": "2017-11-27T11:22:04.024704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 20, 105, 105)\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./ad_frames_new.pickle\", \"rb\")\n",
    "Xy = pickle.load(f)\n",
    "print(Xy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-17T07:41:14.712115Z",
     "start_time": "2017-11-17T07:41:12.730705Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"./_coco_data/train.pickle\", \"rb\")\n",
    "Xt = pickle.load(f)\n",
    "f.close()\n",
    "f = open(\"./_coco_data/val.pickle\", \"rb\")\n",
    "Xv = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Classes Using Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-18T18:45:04.127517Z",
     "start_time": "2017-11-18T18:17:50.866752Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_folder = './Image_Data/COCO'\n",
    "dat_type = 'val'\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "im_list = os.listdir(in_folder)\n",
    "\n",
    "for i, im in enumerate(im_list[2000:3000]):\n",
    "    os.mkdir(str(i+1))    \n",
    "    img = load_img(f'{in_folder}/{im}')  # this is a PIL image\n",
    "    x = img_to_array(img)  # this is a Numpy array with shape (150, 150, 3)\n",
    "#     x = sum([x[:,:,i] for i in range(3)])/3\n",
    "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "    # the .flow() command below generates batches of randomly transformed images\n",
    "    # and saves the results to the `preview/` directory\n",
    "    j = 0\n",
    "    for batch in datagen.flow(x, batch_size=1,\n",
    "                              save_to_dir=f'./{i+1}', save_prefix=f'{dat_type}', save_format='jpeg'):\n",
    "        j += 1\n",
    "        if j > 25:\n",
    "            break  # otherwise the generator would loop indefinitely"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
